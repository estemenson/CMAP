@INPROCEEDINGS{daSilva:2010:ChallengesAndSolutionsInDistributedSoftwareDevelopmentProjectManagement, 
author={da Silva, F.Q.B. and Costa, C. and Frana, A.C.C. and Prikladinicki, R.}, 
booktitle={Global Software Engineering (ICGSE), 2010 5th IEEE International Conference on},
title={Challenges and Solutions in Distributed Software Development Project Management: A Systematic Literature Review}, 
year={2010}, 
month={aug}, 
pages={87 -96}, 
abstract={This paper presents a systematic literature review of the challenges, best practices, models, and tools in Distributed Software Development (DSD) Project Management. The objective is to collect and systematize reported knowledge in terms of what are the difficulties in managing DSD projects, what are the best practices to overcome these difficulties, and how existing models and tools support these practices. We found 54 works related to DSD project management, published between 1998 and 2009. Using the data systematically extracted from these works, we propose an evidence-based DSD project management improvement model. Our contention is that this model can support practitioners and researchers to better understand the landscape of DSD project challenges and devise more effective solutions to improve project management in a distributed setting.},
keywords={DSD;distributed software development project management;systematic literature review;distributed programming;project management;software development management;}, 
doi={10.1109/ICGSE.2010.18} 
}
@INPROCEEDINGS{Ciccozzi:2010:PerformingAProjectDistributedSoftwareDevelopmentCourse, 
author={Ciccozzi, F. and Crnkovic, I.}, 
booktitle={Global Software Engineering (ICGSE), 2010 5th IEEE International Conference on}, 
title={Performing a Project in a Distributed Software Development Course: Lessons Learned}, 
year={2010}, 
month={aug}, 
pages={187 -191}, 
abstract={Distributed software development approaches have to face with several issues like cultural differences, collaboration and communication mechanisms, which can undermine the overall development success if not handled in a proper manner. In order to provide a real environment for students placed in different countries to learn and apply the best practices in distributed software development, a course has been developed jointly by two european universities. The course aims at providing the students an insight in the complexity of distributed development and giving the possibility to work in distributed teams for actual implementations, in order to minimize the gap between theory and practice. This paper describes the course design, challenges, results and success factors, from a students perspective.},
keywords={European university;course design;distributed software development course;computer aided instruction;computer science education;distance learning;educational institutions;groupware;software engineering;}, 
doi={10.1109/ICGSE.2010.29} 
}
@INPROCEEDINGS{Piri:2008:ChallengesGloballyDistributedSoftwareDevelopment, 
author={Piri, A.}, 
booktitle={Global Software Engineering, 2008. ICGSE 2008. IEEE International Conference on},
title={Challenges of Globally Distributed Software Development; Analysis of Problems Related to Social Processes and Group Relations}, 
year={2008}, 
month={aug}, 
pages={264 -268}, 
abstract={When software development is understood as collaborative action between group members, many of the common problems encountered in software development projects can be traced back to social factors of the project. In distributed projects, physical distance between group members limits their face-to-face interaction and thus sets special challenges to communication, which is essential for creating good relations between group members. The goal of this qualitative study is to develop understanding of the importance of social processes and group relations in globally distributed software development, by utilizing literature and earlier research both from software engineering and social sciences.},
keywords={globally distributed software development;social sciences;software development projects;software engineering;project management;software development management;}, 
doi={10.1109/ICGSE.2008.33} 
}
@INPROCEEDINGS{MAK:2006:TaskCoordinationAgileDistributedSoftwareDevelopmentEnvironment, 
author={David K.M. Mak and Philippe B. Kruchten}, 
booktitle={Electrical and Computer Engineering, 2006. CCECE '06. Canadian Conference on},
title={Task Coordination in an Agile Distributed Software Development Environment}, 
year={2006}, 
month={may} , 
pages={606 -611}, 
abstract={As both distributed software development (DSD) and agile development practices become more popular, the problem of task coordination in an agile DSD environment becomes more pertinent. Even though task allocation has been a subject of study for many years, the team dynamics in an agile DSD environment makes the nature of task coordination distinctly different from that in other disciplines. This paper proposes a solution to the problem of remote task allocation and coordination in an agile DSD environment. It combines current practices in software project management, such as object-oriented process modeling and critical-path analysis, and methodologies from other fields, such as workflow management and management science. It also describes NextMove, a Java/Eclipse-based distributed tool that would assist project managers in making day-to-day task allocation decisions, increasing transparency throughout the project, as well as complementing other modes of communication in a DSD environment},
keywords={Java;agile distributed software development environment;critical-path analysis;object-oriented process model;task coordination;workflow management;groupware;object-oriented programming;project management;software development management;team working;}, 
doi={10.1109/CCECE.2006.277524} 
}
@INPROCEEDINGS{Mak:2007:NextMoveAFrameworkforDistributedTaskCoordination, 
author={Mak, D.K.M. and Kruchten, P.B.}, 
booktitle={Software Engineering Conference, 2007. ASWEC 2007. 18th Australian}, 
title={NextMove: A Framework for Distributed Task Coordination}, 
year={2007}, 
month={april}, 
volume={}, 
number={}, 
pages={399 -408}, 
abstract={This paper presents NextMove, a framework that assists project managers in allocating and managing tasks in an agile, distributed development environment. In such environments, managing tasks dynamically is difficult because of the lack of available informal, lightweight communication mechanisms. The framework simulates the project manager's thought processes involved in prioritizing and allocating tasks, by aggregating the variables involved in a software project, such as schedules, feature priorities and team-member attributes, using multi-criteria decision-resolution methodologies. We implemented the framework as a distributed client-server application using Java and MySQL. In addition, we built a simulator to evaluate the effectiveness of the framework. Preliminary simulation results show that, when compared with randomized selection of tasks, NextMove is more efficiently allocates tasks, so in a way that the project is completed sooner.}, 
keywords={Java;MySQL;NextMove;client-server application;distributed task coordination;multicriteria decision-resolution methodology;software project;Java;SQL;client-server systems;project management;software management;}, 
doi={10.1109/ASWEC.2007.33}, 
ISSN={1530-0803}
}
@INPROCEEDINGS{Phalnikar:2009:ApplyingAgilePrinciplesforDistributedSoftwareDevelopment, 
author={Phalnikar, R. and Deshpande, V.S. and Joshi, S.D.}, 
booktitle={Advanced Computer Control, 2009. ICACC '09. International Conference on},
title={Applying Agile Principles for Distributed Software Development}, 
year={2009}, 
month={jan.}, 
pages={535 -539}, 
abstract={The necessity of finding right skilled people, sharing resource and limitation on cost has made distributed software development indispensable. In a distributed development project, but are working collaboratively toward the outcome. Such offshore service providers follow the traditional process models. Agile practices promote development iterations, open collaboration, and process adaptability throughout the life cycle of the project. Adapting these practices in a distributed environment can help distributed development tackle the challenges of cultural incompatibility, leadership struggle and lack of trust. This paper describes the benefits of using agile process and Scrum the iterative incremental process in distributed software development, and proposes two team structures for its implementation.},
keywords={Scrum;agile principle;cultural incompatibility;development iteration;distributed development project;distributed software development;leadership struggle;open collaboration;process adaptability;project life cycle;resource sharing;team structure;distributed programming;software development management;team working;}, 
doi={10.1109/ICACC.2009.93} 
}
@INPROCEEDINGS{Paasivaara:2006:CouldGlobalSoftwareDevelopmentBenefitfromAgileMethods, 
author={Maria Paasivaara and Casper Lassenius}, 
booktitle={Global Software Engineering, 2006. ICGSE '06. International Conference on}, 
title={Could Global Software Development Benefit from Agile Methods?}, 
year={2006}, 
month={oct. }, 
volume={}, 
number={}, 
pages={109 -113}, 
abstract={At first glance, agile methods and global software development might seem incompatible. Agile methods stress continuous face-to-face communication, whereas communication has been reported as the biggest problem of global software development. One challenge to solve is how to apply agile practices in settings where continuous face-to-face interaction is missing. However, agile methods have been successfully used in distributed projects, indicating that they could benefit global software development. This paper discusses potential benefits and challenges of adopting agile methods in global software development. The literature on real industrial case studies reporting on experiences of using agile methods in distributed projects is still scarce. Therefore we suggest further research on the topic. We present our plans for research in companies using agile methods in their distributed projects. We also intend to test the use of agile principles in globally distributed student projects developing software for industrial clients}, 
keywords={agile methods;distributed projects;face-to-face communication;global software development;distributed programming;software engineering;}, 
doi={10.1109/ICGSE.2006.261222}, 
ISSN={}
}
@INPROCEEDINGS{Cristal:2008:UsageofSCRUMPracticeswithinGlobalCompany, 
author={Cristal, M. and Wildt, D. and Prikladnicki, R.}, 
booktitle={Global Software Engineering, 2008. ICGSE 2008. IEEE International Conference on},
title={Usage of SCRUM Practices within a Global Company}, 
year={2008}, 
month={aug}, 
pages={222 -226}, 
abstract={Global companies that experimented extensive waterfall phased plans are trying to improve their existing processes to expedite team engagement. SCRUM has become an acceptable path to follow for those companies because it comprises project management as part of its practices. SCRUM has been used with the objective of simplifying project control through simple processes, easy to update documentation and higher team iteration over exhaustive documentation. Instead of investing team effort on producing static documentation, SCRUM proposes to focus on team continuous improvement aiming to add value to business processes. The purpose of this industry report is to describe two projects that experimented SCRUM practices within a globally distributed company. This company has development centers across North America, South America and Asia. This report covers challenges faced by the project teams, strengths and practical recommendations of using SCRUM in a globally distributed environment.},
keywords={Asia;North America;SCRUM practices;South America;business processes;distributed software development;globally distributed environment;project management;business data processing;distributed processing;project management;software engineering;}, 
doi={10.1109/ICGSE.2008.34} 
}
@INPROCEEDINGS{Prikladnicki:2008:PatternsofEvolutioninthePracticeofDistributedSoftwareDevelopment, 
author={Prikladnicki, R. and Damian, D. and Audy, J.}, 
booktitle={Global Software Engineering, 2008. ICGSE 2008. IEEE International Conference on},
title={Patterns of Evolution in the Practice of Distributed Software Development in Wholly Owned Subsidiaries: A Preliminary Capability Model}, 
year={2008}, 
month={aug}, 
pages={99 -108}, 
abstract={In this paper, we describe a preliminary capability model that captures patterns of evolution in the practice of distributed software development in internal offshoring projects. In our research we seek to understand how the practices of organizations involved in the internal offshoring of software development evolve over time, from a software engineering perspective, and from the point of view of the subsidiaries. Based on a combination of qualitative and quantitative methods, we propose a capability model that encompasses the evolution of software development activities within and among several subsidiaries owned by an organization.},
keywords={capability maturity model;distributed software development;evolution pattern;internal offshoring project team;software engineering perspective;Capability Maturity Model;outsourcing;project management;software development management;software prototyping;team working;}, 
doi={10.1109/ICGSE.2008.36} 
}
@ARTICLE{Rodriguez:2010:TechnologiesandToolsforDistributedTeams, 
author={Rodriguez, J.P. and Ebert, C. and Vizcaino, A.}, 
journal={Software, IEEE},
title={Technologies and Tools for Distributed Teams}, 
year={2010}, 
month={sept.-oct.}, 
volume={27}, 
number={5}, 
pages={10-14}, 
abstract={Software development today is typically a team effort with team members in different geographical places. You might regret that teamwork isn't what it used to be, but you also might want to look toward technologies and tools that support distributed teamwork. Authors Javier Portillo Rodriguez, Aurora Vizcaino, and I provide an overview of such technologies with many tools examples, starting with technologies such as Jazz and then showing how users can orchestrate individual tools in a distributed context.},
keywords={Google Apps;IBM Jazz;Lotus;Microsoft SharePoint;distributed teamwork;software development;software tools;distributed processing;groupware;software tools;}, 
doi={10.1109/MS.2010.126}, 
ISSN={0740-7459}
}
@INPROCEEDINGS{Mudumba:2010:ANewPerspectiveonGDSDRiskManagement:AgileRiskManagement,
author={Mudumba, V. and One-Ki, Lee},
booktitle={Global Software Engineering (ICGSE), 2010 5th IEEE International Conference on},
title={A New Perspective on GDSD Risk Management: Agile Risk Management},
year={2010},
month={aug},
pages={219-227},
abstract={Risk management in globally distributed software development (GDSD) projects is becoming a critical area of concern for practitioners. The risks in GDSD projects can be dynamic due to the multiplicity in various aspects of GDSD projects (e.g., multi-locations, multi-cultures, multi-groups, multi-standards, and multi-technologies). This multiplicity nature leads to dynamic interactions among the internal (i.e., people, process, and technology) and external elements of a GDSD project. This study aims to develop a new framework to identify the dynamic risks in GDSD projects and mitigate them using agile risk management practices. We reflect the proposed framework on a case of GDSD project in the literature, which experienced high multiplicity and thus high dynamics in its project management.},
keywords={agile risk management;dynamic risks;globally distributed software development projects;project management;distributed processing;risk management;software development management;}, 
doi={10.1109/ICGSE.2010.33}
}
@INPROCEEDINGS{Tsirakidis:2009:IdentificationofSuccessandFailureFactorsofTwoAgileSoftwareDevelopmentTeamsinanOpenSourceOrganization, 
author={Tsirakidis, P. and Kobler, F. and Krcmar, H.}, 
booktitle={Global Software Engineering, 2009. ICGSE 2009. Fourth IEEE International Conference on}, 
title={Identification of Success and Failure Factors of Two Agile Software Development Teams in an Open Source Organization}, 
year={2009}, 
month={july}, 
pages={295 -296}, 
abstract={Agile software development methods and free/libre open source development have been two embracing movements in the software industry for more than a decade. However, little is known about the composition of both while today a variety of studies provide us with key characteristics of each one. The study extracts the similarities and differences of both topics by means of an extensive literature review focusing on teams as research unit. Furthermore this study investigates two agile software development teams in an open source organization based on an explorative research design. The focus is on the empirical identification of success and failure in the application of agile methods in teams with open source background, structure and characteristics and in comparison with the literature findings. This study is still in progress, however first results as well as the methodology will be presented hereafter.},
keywords={agile software development;free/libre open source development;software development management;}, 
doi={"10.1109/ICGSE.2009.42"} 
}
@INPROCEEDINGS{Gamma:2005:AgileOpenSourceDistributedOnTimeInsidetheEclipseDevelopmentProcess, 
author={Gamma, E.}, 
booktitle={Software Engineering, 2005. ICSE 2005. Proceedings. 27th International Conference on},
title={Agile, open source, distributed, and on-time - inside the Eclipse development process}, 
year={2005}, 
month={may}, 
pages={ 4}, 
abstract={Summary form only given. Eclipse is a widely recognized open source project dedicated to providing a platform for developing integrated tools. Throughout the history of Eclipse the development team was successful in hitting projected delivery dates with precision and quality. This isn't possible without a team strongly committed to ship quality software. How is this really done? How does Eclipse achieve quality and just-in-time delivery? This paper sheds light on the key practices of the Eclipse development process - from the development mantras "always beta", "milestones first", "API first", and "performance first" to practices such as ensuring quality through multiple feedback loops. The author reflects on proven practices for managing a large project performed by geographically dispersed teams and open source contributors in a highly competitive market. Most of these practices have evolved in the open source project, but they are equally applicable to closed source projects and help to improve quality, timeliness and reduce development stress in both types of environments.},
keywords={ Eclipse development process; agile open source distributed on-time programming; integrated tools development; just-in-time delivery; multiple feedback loops; project management; distributed programming; programming environments; project management; public domain software; software development management; software tools;}, 
doi={"10.1109/ICSE.2005.1553528"} 
}
@INPROCEEDINGS{During:2006:TroubleInParadiseTheOpenSourceProjectPyPyEUFundingAndAgilePractices, 
author={During, B.}, 
booktitle={Agile Conference, 2006}, 
title={Trouble in paradise: the open source project PyPy, EU-funding and agile practices}, 
year={2006}, 
month={july}, 
pages={11 pp. -231}, 
abstract={PyPy is an open source project, partly funded by the European Union, employing agile techniques evolved within the Python Community such as "sprint-driven development". The project started as a grass-root F/OSS effort in late 2002 and received EU-funding from December 2004 until November 2006. In this paper we present the various influencing factors that creates the hybrid project process that is PyPy. These influencing factors are the F/OSS Python Community (climate of the community from which PyPy grew from), agile practices (such as the Python community evolved technique of "sprinting") and the EU funding practices (resource tracking and reporting) impacting the project. These influencing factors laid the foundation for the custom-made project process that makes this unique hybrid project work. The main factor for driving this process is the skills of the team of core developers instigating the project. PyPy, with its open and transparent communication and collaborative work style, is again a proof that the best agile practice is the people factor},
keywords={EU funding practices;F/OSS Python Community;PyPy open source project;agile practices;collaborative work style;custom-made project process;open communication;transparent communication;project management;public domain software;software development management;team working;}, 
doi={10.1109/AGILE.2006.58} 
}
@INPROCEEDINGS{Shawky:2010:APracticalMeasureForTheAgilityOfSoftwareDevelopmentProcesses, 
author={Shawky, D.M. and Ali, A.F.}, 
booktitle={Computer Technology and Development (ICCTD), 2010 2nd International Conference on},
title={A practical measure for the agility of software development processes}, 
year={2010}, 
month={nov.}, 
pages={230 -234}, 
abstract={In the software industry, a large number of projects fail and billions of dollars are spent on failed software projects. Lack of an end user involvement, poor requirements, and unrealistic schedules are some of the top reasons of such failure. Agile software development is an approach that addresses these problems through a real communication between programmers and customers. Thus, there is a need to quantify software agility. In this paper, an approach for quantifying software agility is provided by modeling the key concepts in agile software and proposing a measure that can be used in representing how agile a software development process is. The proposed measure employs information entropy as the main concept related to software agility. The suggested measure is tested on two open source case studies. Experimental results demonstrate the validity and suitability of the agility measure.},
keywords={end user involvement;information entropy;poor requirements;software agility quantification;software development processes;software industry;unrealistic schedules;entropy;public domain software;software development management;software metrics;software prototyping;}, 
doi={10.1109/ICCTD.2010.5645881} 
}
@INPROCEEDINGS{Nevo:2011:EnhancingThePerformanceOfSoftwareDevelopmentVirtualTeamsThroughTheUseOfAgileMethods, 
author={Nevo, S. and Chengalur-Smith, I.}, 
booktitle={System Sciences (HICSS), 2011 44th Hawaii International Conference on}, 
title={Enhancing the Performance of Software Development Virtual Teams through the Use of Agile Methods: A Pilot Study}, 
year={2011}, 
month={jan.}, 
pages={1 -10}, 
abstract={This paper develops a conceptual model that explicates the role of synchronous communication media in enabling - directly and indirectly, via social presence - virtual software development teams to adopt and apply Agile methods. In turn, Agile methods, as well as perceived social presence, are theorized to have a positive impact on communication convergence and transactive memory. Ultimately, these outcomes are formulated as direct antecedents of virtual team performance. A pilot study of 40 Free/Libre Open Source Software (FLOSS) teams provides preliminary supporting evidence for the conceptual model.},
keywords={agile methods;communication convergence;direct antecedents;free-libre open source software;perceived social presence;synchronous communication media;transactive memory;virtual software development teams;groupware;public domain software;software prototyping;virtual reality;}, 
doi={10.1109/HICSS.2011.186}, 
ISSN={1530-1605}}
@incollection {Karsten:2007:TheCreationOfADistributedAgileTeam,
   author = {Karsten, Paul and Cannizzo, Fabrizio},
   affiliation = {British Telecom PLC, BT Centre, 81 Newgate Street, London (UK), EC1A 7AJ  },
   title = {The Creation of a Distributed Agile Team},
   booktitle = {Agile Processes in Software Engineering and Extreme Programming},
   series = {Lecture Notes in Computer Science},
   editor = {Concas, Giulio and Damiani, Ernesto and Scotto, Marco and Succi, Giancarlo},
   publisher = {Springer Berlin / Heidelberg},
   pages = {235-239},
   volume = {4536},
   abstract={This report tells the story of a project started one and a half years ago in BT and how the enthusiasm and dedication on applying agile methodologies has allowed the team to grow while successfully delivering on their goals. It describes the process that has been put in place to manage the project and develop the software; it also tells how some of the practices initially applied have been then changed and adapted to make them fit for the distributed and unique nature of the team.},
   url = {\url{http://dx.doi.org/10.1007/978-3-540-73101-6_44}},
   year = {2007}
}
@incollection {Petersen:2011:AnalysisOfEmergentAndEvolvingInformationTheAgilePlanningCase,
   author = {Petersen, Rasmus Rosenqvist and Wiil, Uffe Kock},
   affiliation = {The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Campusvej 55, 5230 Odense M, Denmark},
   title = {Analysis of Emergent and Evolving Information: The Agile Planning Case},
   booktitle = {Software and Data Technologies},
   series = {Communications in Computer and Information Science},
   editor = {Cordeiro, Jos� and Ranchordas, AlpeshKumar and Shishkov, Boris},
   publisher = {Springer Berlin Heidelberg},
   isbn = {978-3-642-20116-5},
   keyword = {Computer Science},
   pages = {263-276},
   volume = {50},
   abstract={Some information structures are by nature emergent and evolving and as a consequence the retrievable knowledge keeps shifting patterns like a kaleidoscope. Hence, information analysis can be a complex and tedious task. The planning task of agile teams is an example of such a complex information analysis task. In this paper, we present a lightweight planning tool. ASAP is inspired by concepts and principles from spatial hypertext, which have proven successful in supporting information analysis tasks. ASAP runs on a large interactive vertical display on which electronic task cards can be organized into iterations and releases using card hierarchies and separators (a novel visual concept). Several views of the evolving plan are automatically generated to assist the agile team with overviews of tasks, estimates, and assignments. Views are instantly updated to reflect changes to the plan.},
   url = {\url{http://dx.doi.org/10.1007/978-3-642-20116-5_20}},
   year = {2011}
}
@incollection {Morgan:2007:UsingHorizontalDisplaysForDistributedAndCollocatedAgilePlanning,
   author = {Morgan, Robert and Walny, Jagoda and Kolenda, Henning and Ginez, Estaban and Maurer, Frank},
   affiliation = {Department of Computer Science, University of Calgary, 2500 University Dr. NW, Calgary, AB, T2N 1N4 Canada Canada},
   title = {Using Horizontal Displays for Distributed and Collocated Agile Planning},
   booktitle = {Agile Processes in Software Engineering and Extreme Programming},
   series = {Lecture Notes in Computer Science},
   editor = {Concas, Giulio and Damiani, Ernesto and Scotto, Marco and Succi, Giancarlo},
   publisher = {Springer Berlin / Heidelberg},
   pages = {38-45},
   volume = {4536},
   abstract={Computer-supported environments for agile project planning are often limited by the capability of the hardware to support collaborative work. We present DAP, a tool developed to aid distributed and collocated teams in agile planning meetings. Designed with a multi-client architecture, it works on standard desktop computers and digital tables. Using digital tables, DAP emulates index card based planning without requiring team members to be in the same room.},
   url = {\url{http://dx.doi.org/10.1007/978-3-540-73101-6_6}},
   year = {2007}
}
@INPROCEEDINGS{Korhonen:2010:EvaluatingTheEffectOfAgileMethodsOnSoftwareDefectDataAndDefectReportingPractices, 
author={Korhonen, K.}, 
booktitle={Quality of Information and Communications Technology (QUATIC), 2010 Seventh International Conference on the},
title={Evaluating the Effect of Agile Methods on Software Defect Data and Defect Reporting Practices - A Case Study}, 
year={2010},
month={oct.}, 
pages={35 -43}, 
abstract={In large, traditional software development projects, the number of defects can be considerably high. Agile methods promise code quality improvement, but while embracing the agile methods, software development organizations have realized that defects still do exist and must be managed. When the development is distributed over several sites, defect management can become even more challenging. In this study we analyzed defect data in a large multi-site organization during the first twelve months of their agile transformation. Complementing information was gathered by a survey, which was conducted in the organization twice: after six and after twelve months of starting the agile transformation. The results indicate that the defect reporting practices changed after the agile adoption was started, the defect inflow was more stable and the defect closing speed improved.},
keywords={agile methods;agile transformation;code quality improvement;defect reporting practices;multisite organization;software defect data;software development projects;software development management;software quality;}, 
doi={10.1109/QUATIC.2010.18} 
}
@INPROCEEDINGS{Nardi:1991:BeyondModels, 
author={Nardi, B.A. and Zarmer, C.L.}, 
booktitle={System Sciences, 1991. Proceedings of the Twenty-Fourth Annual Hawaii International Conference on}, 
title={Beyond models and metaphors: visual formalisms in user interface design}, 
year={1991}, 
month=jan, 
volume={ii}, 
number={}, 
pages={478-493 vol.2}, 
abstract={The user interface has both syntactic functions-supplying commands and arguments to programs-and semantic functions-visually presenting application semantics and supporting problem solving cognition. The authors argue that though both functions are important, it is time to devote more resources to the problems of the semantic interface. Complex problem solving activities, e.g. for design and analysis tasks, benefit from clear visualizations of application semantics in the user interface. Designing the semantic interface requires computational building blocks capable of representing and visually presenting application semantics in a clear, precise way. The authors argue that neither mental models not metaphors provide a basis for designing and implementing such building blocks, but that visual formalisms do. They compare the benefits of mental models, metaphors and visual formalisms as the basis for designing the user interface, with particular attention to the practical solutions each provides to application developers}, 
keywords={analysis tasks;application developers;application semantics;clear visualizations;computational building blocks;mental models;metaphors;problem solving cognition;semantic functions;semantic interface;user interface design;visual formalisms;graphical user interfaces;human factors;interactive systems;problem solving;}, 
doi={10.1109/HICSS.1991.184010}, 
ISSN={}}
@INPROCEEDINGS{White:2010:ApplicationOfCognitiveTheoriesAndKnowledgeManagementToRequirementsEngineering, 
author={White, S.M.}, 
booktitle={Systems Conference, 2010 4th Annual IEEE}, 
title={Application of cognitive theories and knowledge management to requirements engineering}, 
year={2010}, 
month=april, 
volume={}, 
number={}, 
pages={137-142}, 
abstract={In this paper, we discuss the systems engineering process during front-end phases, with emphasis on capturing requirements related knowledge by inter-organizational and systems of systems teams. We discuss four dimensions of knowledge identified in the knowledge management literature, and apply them to the capture of requirements related knowledge. We discuss and compare three cognitive theories (Situated Action, Activity Theory, and Distributed Cognition) and examine them with respect to improving system requirements engineering and analysis. We find that research in KM and cognition offers significant ideas and insights for improving the requirements process.}, 
keywords={activity theory;cognitive theory;distributed cognition;front end phases;knowledge management;requirements related knowledge;situated action;system requirements engineering;systems engineering process;knowledge management;systems analysis;systems engineering;}, 
doi={10.1109/SYSTEMS.2010.5482489}, 
ISSN={}}
@INPROCEEDINGS{McQuay:2000:DistributedCollaborativeEnvironmentsForThe21stCenturyEngineer, 
author={McQuay, W.K.}, 
booktitle={National Aerospace and Electronics Conference, 2000. NAECON 2000. Proceedings of the IEEE 2000}, 
title={Distributed collaborative environments for the 21st century engineer}, 
year={2000}, 
month={}, 
volume={}, 
number={}, 
pages={407-414}, 
abstract={Distributed collaboration is an emerging technology for the 21st century that will significantly change how business is conducted in the defense and commercial sectors. Collaboration involves two or more geographically dispersed individuals working together to share and exchange data, information, knowledge, and actions. The product of the collaboration is defined broadly to include, for example, writing a report, creating software, designing hardware, or developing an alternative course of action for the commander. Distributed collaborative environments (DCE) provide the framework and integrate models, simulations, domain specific tools, and virtual test beds to facilitate collaboration between the multiple disciplines needed in the enterprise. The Air Force Research Laboratory (AFRL) is conducting a leading edge program in developing distributed collaborative technologies targeted to the Air Force's implementation of a simulation-aided acquisition and test process, distributed mission training, and distributed command and control. Geographically separated teams of government and industry engineers, scientists, managers, and procurement specialists will be able to jointly develop advanced technology products. The team will be able to access widely distributed computer-based engineering tools, models and simulations, databases, and research facilities. DCE will reduce the cost of development and ownership, reduce duplication of effort, improve quality of design, and result in faster time to product. The research is focusing on the open standards agent-based framework, product and process modelling, structural architecture, and the integration technologies-the glue to integrate the software components. DCE is the underlying infrastructure that makes communication between the diverse simulations and other assets possible and manages the overall flow of the experiment. The AFRL Collaborative Environment concept will foster a major cultural change in how the acquisition, training, and operational communities conduct business}, 
keywords={ Air Force Research Laboratory; aerospace engineering; defence industry; distributed collaborative environment; future developments; aerospace computing; distributed processing; groupware; military computing; technological forecasting;}, 
doi={10.1109/NAECON.2000.894939}, 
ISSN={}}
@ARTICLE{Bresciani:2009:TheBenefitsOfSynchronousCollaborativeInformationVisualization, 
author={Bresciani, S. and Eppler, M.J.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation}, 
year={2009}, 
month={nov.-dec. }, 
volume={15}, 
number={6}, 
pages={1073-1080}, 
abstract={A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a- - nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.}, 
keywords={data analysis;group annotation;knowledge sharing;statistical analysis;suboptimal visualization;synchronous collaborative information visualization;synchronous group knowledge work;data analysis;data visualisation;statistical analysis;}, 
doi={10.1109/TVCG.2009.188}, 
ISSN={1077-2626}}
@INPROCEEDINGS{Bresciani:2010:ChoosingKnowledgeVisualizationsToAugmentCognition, 
author={Bresciani, S. and Eppler, M.J.}, 
booktitle={Information Visualisation (IV), 2010 14th International Conference},
title={Choosing Knowledge Visualizations to Augment Cognition: The Managers' View}, 
year={2010}, 
month={july}, 
volume={}, 
number={}, 
pages={355-360}, 
abstract={Growing evidence in the scientific literature and in organizations shows the positive impact of employing conceptual visual representation for individual reasoning, communicating and facilitating meetings in organizations. 116 managers responded a questionnaire on the usefulness of 12 common business visualizations for typical knowledge tasks in organizations. The resulting ranking provides an overview of the comparative suitability of visualizations for generating ideas, sharing knowledge, evaluating options and planning. The findings can be used by organizations for evaluating visual templates as a support for specific knowledge tasks. Theoretical implications include the relationship between the structure level of knowledge visualization forms and convergent/divergent task type. Further implications for theory and practice are discussed.}, 
keywords={business visualizations;cognition;conceptual visual representation;knowledge tasks;knowledge visualizations;cognition;data visualisation;knowledge engineering;}, 
doi={10.1109/IV.2010.56}, 
ISSN={1550-6037},}
@INPROCEEDINGS{Bresciani:2008:ACollaborativeDimensionsFramework, 
author={Bresciani, S. and Blackwell, A.F. and Eppler, M.}, 
booktitle={Hawaii International Conference on System Sciences, Proceedings of the 41st Annual},
title={A Collaborative Dimensions Framework: Understanding the Mediating Role of Conceptual Visualizations in Collaborative Knowledge Work}, 
year={2008}, 
month={jan.}, 
volume={}, 
number={}, 
pages={364}, 
abstract={Facilitating collaborative knowledge work is a crucial issue in management: knowledge is a key corporate asset, but it is typically spread across various people in different organizational functions. In this paper we explore how conceptual visualizations (such as diagrams, visual metaphors, charts, sketches) can be constructed and used as cognitive artefacts that support collaborative knowledge work. In order to facilitate tasks such as the creation and sharing of knowledge in teams, we propose a collaborative dimensions framework as a tool for understanding how visual artefacts can facilitate collaboration in circumstances that involve distributed knowledge. The framework is based on the widespread Cognitive Dimensions of Notation framework and is enriched with criteria from the boundary object paradigm discussed in organization science. The dimensions of the framework are described and then applied to three different visualizations that are used in collaborative knowledge work. A discussion of future research needs concludes the paper.}, 
keywords={boundary object paradigm;collaborative knowledge work;conceptual visualization;knowledge management;organizational function;data visualisation;groupware;knowledge management;}, 
doi={10.1109/HICSS.2008.7}, 
ISSN={1530-1605},}
@INPROCEEDINGS{Zarmer:1992:ACE:ZenAndTheArtOfApplicationBuilding, 
author={Zarmer, C.L. and Nardi, B.A. and Johnson, J. and Miller, J.R.}, 
booktitle={System Sciences, 1992. Proceedings of the Twenty-Fifth Hawaii International Conference on},
title={ACE: Zen and the art of application building}, 
year={1992}, 
month={jan}, 
volume={2}, 
number={}, 
pages={687-698}, 
abstract={Task-specific application development environments enable end users to create their own applications. This is advantageous in two ways: users can draw on their own rich task knowledge to create the applications they really want, and reliance on the scarce, expensive expertise of professional programmers is greatly reduced. Extensible systems such as spreadsheets and statistical packages provide a good model for application construction as they allow end users to create complete applications. Such environments eliminate the need for separate user interface builders; the interface is seamlessly created as the application is developed. In this `Zen' process, there is little difference between application development and user interface development. Further barriers are broken down by creating application development components that can continually be edited and refined, so that distinctions among `editing', `building', `application construction', and `finished application' begin to disappear. The authors describe ACE, an architecture for building task-specific applications, and the software libraries they have developed to implement this architecture. They show how ACE supports the building of task-specific applications via a range of extension mechanisms from interactive editing by end users to programmer-defined subclassing}, 
keywords={ ACE; Zen; application building; interactive editing; programmer-defined subclassing; software libraries; spreadsheets; statistical packages; task specific application development environment; graphical user interfaces; programming environments;}, 
doi={10.1109/HICSS.1992.183320}, 
ISSN={}}
@article{Gershon:1998:Informationvisualization,
 author = {Gershon, Nahum and Eick, Stephen G. and Card, Stuart},
 title = {Information visualization},
 journal = {interactions},
 volume = {5},
 issue = {2},
 month = {March},
 year = {1998},
 issn = {1072-5520},
 pages = {9-15},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/274430.274432},
 doi = {http://doi.acm.org/10.1145/274430.274432},
 acmid = {274432},
 publisher = {ACM},
 address = {New York, NY, USA}
} 
@article {Brodlie:2004:DistributedAndCollaborativeVisualization,
author = {Brodlie, K. W. and Duce, D. A. and Gallop, J. R. and Walton, J. P. R. B. and Wood, J. D.},
title = {Distributed and Collaborative Visualization},
journal = {Computer Graphics Forum},
volume = {23},
number = {2},
publisher = {Blackwell Publishing Ltd.},
issn = {1467-8659},
url = {http://dx.doi.org/10.1111/j.1467-8659.2004.00754.x},
doi = {10.1111/j.1467-8659.2004.00754.x},
pages = {223-251},
keywords = {distributed visualization, collaborative visualization, Grid computing, Web-based visualization, Web Services, reference models, visualization systems, H.5.3. [Group and Organization Interfaces]: Collaborative computing, I.3.2 [Computer Graphics]: Distributed/network graphics, I.3.8 [Computer Graphics]: Applications},
year = {2004},
abstract = {
Visualization is a powerful tool for analyzing data and presenting results in science, engineering and medicine. This paper reviews ways in which it can be used in distributed and/or collaborative environments. Distributed visualization addresses a number of resource allocation problems, including the location of processing close to data for the minimization of data traffic. The advent of the Grid Computing paradigm and the link to Web Services provides fresh challenges and opportunities for distributed visualization—including the close coupling of simulations and visualizations in a steering environment. Recent developments in collaboration have seen the growth of specialized facilities (such as Access Grid) which have supplemented traditional desktop video conferencing using the Internet and multicast communications. Collaboration allows multiple users—possibly at remote sites—to take part in the visualization process at levels which range from the viewing of images to the shared control of the visualization methods. In this review, we present a model framework for distributed and collaborative visualization and assess a selection of visualization systems and frameworks for their use in a distributed or collaborative environment. We also discuss some examples of enabling technology and review recent work from research projects in this field.},
}
@inproceedings{Zuk:2006:HeuristicsForInformationVisualizationEvaluation,
 author = {Zuk, Torre and Schlesier, Lothar and Neumann, Petra and Hancock, Mark S. and Carpendale, Sheelagh},
 title = {Heuristics for information visualization evaluation},
 booktitle = {Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization},
 series = {BELIV '06},
 year = {2006},
 isbn = {1-59593-562-2},
 location = {Venice, Italy},
 pages = {1-6},
 numpages = {6},
 abstract={Heuristic evaluation is a well known discount evaluation technique in human-computer interaction (HCI) but has not been utilized in information visualization (InfoVis) to the same extent. While several sets of heuristics have been used or proposed for InfoVis, it is not yet known what kind of heuristics are useful for finding general InfoVis problems. We performed a meta-analysis with the goal of exploring the issues of heuristic evaluation for InfoVis. This meta-analysis concentrates on issues pertaining to the selection and organization of heuristics, and the process itself. For this purpose, we used three sets of previously published heuristics to assess a visual decision support system that is used to examine simulation data. The meta-analysis shows that the evaluation process and results have a high dependency on the heuristics and the types of evaluators chosen. We describe issues related to interpretation, redundancy, and conflict in heuristics. We also provide a discussion of generalizability and categorization of these heuristics.},
 url = {http://doi.acm.org/10.1145/1168149.1168162},
 doi = {http://doi.acm.org/10.1145/1168149.1168162},
 acmid = {1168162},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@inproceedings{Kulyk:2008:SituationalAwareness,
 author = {Kulyk, Olga and van der Veer, Gerrit and van Dijk, Betsy},
 title = {Situational awareness support to enhance teamwork in collaborative environments},
 booktitle = {Proceedings of the 15th European conference on Cognitive ergonomics: the ergonomics of cool interaction},
 series = {ECCE '08},
 year = {2008},
 isbn = {978-1-60558-399-0},
 location = {Funchal, Portugal},
 pages = {1-5},
 articleno = {5},
 numpages = {5},
 abstract={Motivation -- Modern collaborative environments often provide an overwhelming amount of visual information on multiple displays. The multitude of personal and shared interaction devices leads to lack of awareness of team members on ongoing activities, and awareness of who is in control of shared artefacts. This research addresses the situational awareness (SA) support of multidisciplinary teams in co-located collaborative environments. This work aims at getting insights into design and evaluation of large displays systems that afford SA and effective teamwork.

Research approach -- An exploratory (Wassink et al., 2008) as well as experimental approach is applied. The results of our exploratory studies, which included contextual observations, interviews and task analysis, have been translated into requirements for support of multidisciplinary teamwork in life sciences (Kulyk and Wassink, 2006). Currently we perform practical case studies in omics experimentation domain (Kulyk et al., 2007). In a first controlled study we assess shared SA of team members, providing new SA concepts on a shared large display.

Findings/Design -- We developed several concepts for SA support on large shared displays. Memory Board is an interface that automatically stores and visualizes the activity history on a shared large display. This allows team members to retrieve annotations made on previous slides or visualizations. It also provides awareness of who is currently in control of any display, and who is manipulating and annotating the visualizations. Highlighting on Demand interface enables a team member to highlight or fade out any part of a display using any personal interaction device.

Take away message -- Designing systems that support situational awareness is of great importance to ensure that a collaborative environment enables efficient and effective team coordination and decision making.},
 url = {http://doi.acm.org/10.1145/1473018.1473025},
 doi = {http://doi.acm.org/10.1145/1473018.1473025},
 acmid = {1473025},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative working environment, scientists, shared displays, situational awareness, teamwork},
} 
@book{Helander:1988:HandbookOfHumanComputerInteraction,
	author={Martin Helander},
	year={1988},
	title={Handbook of human-computer interaction},
	publisher={North-Holland ; Sole distributors for the U.S.A. and Canada, Elsevier Science Pub. Co},
	address={Amsterdam ; New York : New York, N.Y., U.S.A},
	keywords={Human-computer interaction.},
	isbn={0444705368},
	language={eng}
}
@InBook{Carroll:1988:InterfaceMetaphorsAndUserInterfaceDesign,
  author = 	 {J. M. Carroll and R. L. Mack and W. A. Kellogg},
  crssref = {Helander:1988:HandbookOfHumanComputerInteraction},
  title = 	 {Interface Metaphors And User Interface Design},
  year = 	 {1988},
  pages = 	 {67-85}
}
@article{Carroll:1985:MetaphorComputingSystems,
title = {Metaphor, computing systems, and active learning},
journal = {International Journal of Man-Machine Studies},
volume = {22},
number = {1},
pages = {39-57},
year = {1985},
note = {},
issn = {0020-7373},
doi = {DOI: 10.1016/S0020-7373(85)80076-6},
url = {http://www.sciencedirect.com/science/article/B6WGS-4T6NC5P-5/2/ca97325ff6dd64e97613e82e2ce783a8},
author = {John M. Carroll and Robert L. Mack},
abstract = {
Recent discussion has resolved the question of how prior knowledge organizes new learning into the technical definition and study of "metaphor". Some theorists have adopted an "operational" approach, focusing on the manifest effects of suggesting metaphoric comparisons to learners. Some have resolved the question formally into a "structural" definition of metaphor. However, structural and operation approaches typically ignore the goal-directed learner-initiated learning process through which metaphors become relevant and effective in learning. Taking this process seriously affords an analysis of metaphor that explains why metaphors are intrinsically open-ended and how their open-endedness stimulates the construction of mental models.}
}
@InBook{Blackwell:2003:NotationalSystems,
  author = 	 {Blackwell, A.F.  and Green, T.R.G. },
  booktitle = {J.M. Carroll (Ed.), HCI Models, Theories and Frameworks: Toward a multidisciplinary science},
  title = 	 {Notational systems the cognitive dimensions of notations framework},
  publisher = 	 {Morgan Kaufmann},
  year = 	 {2003},
  pages = 	 {103-134}
}
@inproceedings{Carroll:1988:InterfaceMetaphors,
author = {J. M. Carroll and R. L. Mack and W. A. Kellogg},
title = {Interface metaphors and user interface design},
booktitle = {Human-Computer Interaction},
year = {1988},
masid = {1325139}
}
@ARTICLE{Carroll:1982:MetaphorAndTheCognitiveRepresentation, 
author={Carroll, John M. and Thomas, John C.}, 
journal={Systems, Man and Cybernetics, IEEE Transactions on}, title={Metaphor and the Cognitive Representation of Computing Systems}, 
year={1982}, 
month={march }, 
volume={12}, 
number={2}, 
pages={107-116}, 
abstract={In learning, people develop new cognitive structures by metaphorically extending old ones. The metaphors spontaneously generated by new users will predict the ease with which they can master a computer system. Systems which through their interface suggest inefficacious metaphors will accordingly be more difficult to learn and to that extent unacceptable.}, 
keywords={}, 
doi={10.1109/TSMC.1982.4308795}, 
ISSN={0018-9472}}
@article{Hundhausen:2005:CommunicativeDimensionsFramework,
author = {Christopher D. Hundhausen},
title = {Using end-user visualization environments to mediate conversations: a 'Communicative Dimensions' framework},
journal = {Journal of Visual Languages and Computing},
volume = {16},
year = {2005},
pages = {153-185},
doi = {10.1016/j.jvlc.2004.11.002},
abstract={An end user visualization environmentai mst oem power end users tocreat e graphicalrepresent ations of phenomena withina sci entificdom ain of interest. Research intoend user visualization environmentshas traditionallyfocused on developing the human-computer interaction necessary to enable the quick and easy},
masid = {2175256}
}
@article{Hundhausen:2005:CommunicativeDimensionsFramework1,
author = {Christopher D. Hundhausen},
title = {Using end-user visualization environments to mediate conversations: a 'Communicative Dimensions' framework},
journal = {Journal of Visual Languages and Computing},
volume = {16},
year = {2005},
pages = {153--185},
doi = {10.1016/j.jvlc.2004.11.002},
abstract={An end user visualization environmentai mst oem power end users tocreat e graphicalrepresent ations of phenomena withina sci entificdom ain of interest. Research intoend user visualization environmentshas traditionallyfocused on developing the human-computer interaction necessary to enable the quick and easy},
masid = {2175256}
}
@article{Star:1989:BoundaryObjects,
author = {Star, Susan Leigh and Griesemer, James R.}, 
title = {Institutional Ecology, `Translations' and Boundary Objects: Amateurs and Professionals in Berkeley's Museum of Vertebrate Zoology, 1907-39}, 
volume = {19}, 
number = {3}, 
pages = {387-420}, 
year = {1989}, 
doi = {10.1177/030631289019003001}, 
abstract ={
               Scientific work is heterogeneous, requiring many different actors and viewpoints. It also requires cooperation. The two create tension between divergent viewpoints and the need for generalizable findings. We present a model of how one group of actors managed this tension. It draws on the work of amateurs, professionals, administrators and others connected to the Museum of Vertebrate Zoology at the University of California, Berkeley, during its early years. Extending the Latour-Callon model of interessement, two major activities are central for translating between viewpoints: standardization of methods, and the development of `boundary objects'. Boundary objects are both adaptable to different viewpoints and robust enough to maintain identity across them. We distinguish four types of boundary objects: repositories, ideal types, coincident boundaries and standardized forms.
            }, 
URL = {http://sss.sagepub.com/content/19/3/387.abstract}, 
eprint = {http://sss.sagepub.com/content/19/3/387.full.pdf+html}, 
journal = {Social Studies of Science}}

@book{Brand:1986:RepresentationOfknowledge,
    author={Myles Brand and Robert M. Harnish},
    year={1986},
    title={The Representation of knowledge and belief},
    publisher={University of Arizona Press},
    address={Tucson},
    keywords={Belief and doubt Congresses.; Knowledge representation (Information theory) Congresses.; Cognition Congresses.},
    isbn={0816509719},
    language={eng}}

@inbook{Rips:1986:MentalMuddles,
 author = {Rips, L},
 chapter = {Mental Muddles},
 crossref = {Brand:RepresentationOfknowledge},
 book = {M. Brand and R. M. Harnish (Eds.), The representation of knowledge and belief},
 year = {1986},
 isbn = {0-816-50971-9},
 pages = {258-286},
 numpages = {28},
 publisher = {University of Arizona Press},
 address = {Tucson, AZ}}
@inproceedings{Reisberg:1987:ExternalRepresentations,
  author    = {Reisberg, D.},
  title     = {External Representations and the Advantages of Externalizing One's Thoughts},
  booktitle = {Proceedings of the 9th Annual Conference of the Cognitive Science Society },
  year      = {1987},
  pages = {281-293},
  publisher = {Hillsdale, N.J.: Erlbaum Associates}}

@ARTICLE{Kintsch:1988:TheRoleOfKnowledge,
    author = {Walter Kintsch},
    title = {The role of knowledge in discourse comprehension: A construction-integration model},
    journal = {Psychological Review},
    year = {1988},
    volume = {95},
    pages = {163-182}}

@inproceedings{Nardi:1990:TheSpreadsheetInterface,
  author    = {Bonnie A. Nardi and James R. Miller},
  title     = {The spreadsheet interface: A basis for end user programming},
  booktitle = {INTERACT},
  year      = {1990},
  pages     = {977-983},
  crossref  = {DBLP:conf/interact/1990},
  bibsource = {DBLP, http://dblp.uni-trier.de}}

@proceedings{Diaper:1990:HumanComputerInteraction,
  editor    = {Dan Diaper and
               David J. Gilmore and
               Gilbert Cockton and
               Brian Shackel},
  title     = {Human-Computer Interaction, INTERACT '90, Proceedings of
               the IFIP TC13 Third Interantional Conference on Human-Computer
               Interaction, Cambridge, UK, 27-31 August, 1990},
  booktitle = {INTERACT},
  publisher = {North-Holland},
  year      = {1990},
  isbn      = {0-444-88817-9},
  bibsource = {DBLP, http://dblp.uni-trier.de}}
 
@inbook{Nielsen:1994:HeuristicEvaluation,
 author = {Nielsen, Jakob},
 title = {Heuristic evaluation},
 book = {Usability inspection methods},
 year = {1994},
 isbn = {0-471-01877-5},
 pages = {25-62},
 numpages = {38},
 url = {http://portal.acm.org/citation.cfm?id=189200.189209},
 acmid = {189209},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA}}

@inproceedings{Nielsen:1995:UsabilityInspectionMethods,
 author = {Nielsen, Jakob},
 title = {Usability inspection methods},
 booktitle = {Conference companion on Human factors in computing systems},
 series = {CHI '95},
 year = {1995},
 isbn = {0-89791-755-3},
 location = {Denver, Colorado, United States},
 pages = {377-378},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/223355.223730},
 doi = {http://doi.acm.org/10.1145/223355.223730},
 acmid = {223730},
 publisher = {ACM},
 address = {New York, NY, USA}}

@article{Shneiderman:1987:DesigningUserInterfaceStrategies,
 author = {Shneiderman, Ben},
 title = {Designing the user interface strategies for effective human-computer interaction},
 journal = {SIGBIO Newsl.},
 volume = {9},
 issue = {1},
 month = {March},
 year = {1987},
 issn = {0163-5697},
 pages = {6},
 url = {http://portal.acm.org/citation.cfm?id=25065.950626},
 acmid = {950626},
 publisher = {ACM},
 address = {New York, NY, USA}}

@article{Tory:2005:EvaluatingVisualizations,
 author = {Tory, Melanie and Moller, Torsten},
 title = {Evaluating Visualizations: Do Expert Reviews Work?},
 journal = {IEEE Comput. Graph. Appl.},
 volume = {25},
 issue = {5},
 month = {September},
 year = {2005},
 issn = {0272-1716},
 pages = {8-11},
 numpages = {4},
 url = {http://portal.acm.org/citation.cfm?id=1092228.1092239},
 doi = {10.1109/MCG.2005.102},
 acmid = {1092239},
 abstract={Visualization research generates beautiful images and impressive interactive systems. Such developments make fascinating demos, but how do we know if they are actually useful for real people doing real tasks? If the interaction is awkward or we have not carefully considered users' needs, even the most well-intentioned and technically developed visual display will be ineffective. Emphasis on evaluating visualizations is growing. User studies of perceptual phenomena related to visualization and comparisons of visualization tools are becoming hot topics in the visualization literature. But, along the way, researchers are discovering that user study design is rarely straightforward.},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {expert reviews, visualization, heuristics}}

@article{Johnson:1993:ACE:BuildingInteractiveGraphicalApplications,
 author = {Johnson, Jeff A. and Nardi, Bonnie A. and Zarmer, Craig L. and Miller, James R.},
 title = {ACE: building interactive graphical applications},
 journal = {Commun. ACM},
 volume = {36},
 issue = {4},
 month = {April},
 year = {1993},
 issn = {0001-0782},
 pages = {40-55},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/255950.153576},
 doi = {http://doi.acm.org/10.1145/255950.153576},
 acmid = {153576},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {UI, UIMS, spreadsheet, toolkit}} 
@book{Norman:1986:UserCenteredSystemDesign,
    author={Donald A. Norman and Stephen W. Draper},
    year={1986},
    title={User centered system design : new perspectives on human-computer interaction},
    publisher={L. Erlbaum Associates},
    address={Hillsdale, N.J},
    note={Includes index.},
    keywords={Human-computer interaction.; System design.},
    isbn={0898597811 (pbk.)},
    language={eng}
}
@article{Hutchins:1985:DirectManipulationIinterfaces,
 author = {Hutchins, Edwin L. and Hollan, James D. and Norman, Donald A.},
 title = {Direct manipulation interfaces},
 journal = {Hum.-Comput. Interact.},
 volume = {1},
 issue = {4},
 month = {December},
 year = {1985},
 issn = {0737-0024},
 pages = {311--338},
 numpages = {28},
 url = {http://dx.doi.org/10.1207/s15327051hci0104_2},
 doi = {http://dx.doi.org/10.1207/s15327051hci0104_2},
 acmid = {1453235},
 abstract={Direct manipulation has been lauded as a good form of interface design, and some interfaces that have this property have been well received by users. In this article we seek a cognitive account of both the advantages and disadvantages of direct manipulation interfaces. We identify two underlying phenomena that give rise to the feeling of directness. One deals with the information processing distance between the user's intentions and the facilities provided by the machine. Reduction of this distance makes the interface feel direct by reducing the effort required of the user to accomplish goals. The second phenomenon concerns the relation between the input and output vocabularies of the interface language. In particular, direct manipulation requires that the system provide representations of objects that behave as if they are the objects themselves. This provides the feeling of directness of manipulation},
 publisher = {L. Erlbaum Associates Inc.},
 address = {Hillsdale, NJ, USA},
}
@article{Harel:1988:VisualFormalisms,
 author = {Harel, David},
 title = {On visual formalisms},
 journal = {Commun. ACM},
 volume = {31},
 issue = {5},
 month = {May},
 year = {1988},
 issn = {0001-0782},
 pages = {514--530},
 numpages = {17},
 url = {http://doi.acm.org/10.1145/42411.42414},
 doi = {http://doi.acm.org/10.1145/42411.42414},
 abstract={The higraph, a general kind of diagramming object, forms a visual formalism of topological nature. Higraphs are suited for a wide array of applications to databases, knowledge representation, and, most notably, the behavioral specification of complex concurrent systems using the higraph-based language of statecharts.},
 acmid = {42414},
 publisher = {ACM},
 address = {New York, NY, USA}
} 
@article{Furnas:1986:GFV:22339.22342,
 author = {Furnas, G. W.},
 title = {Generalized fisheye views},
 journal = {SIGCHI Bull.},
 issue_date = {April 1986},
 volume = {17},
 issue = {4},
 month = {April},
 year = {1986},
 issn = {0736-6906},
 pages = {16--23},
 numpages = {8},
 abstract={In many contexts, humans often represent their own neighborhood in great detail, yet only major landmarks further away. This suggests that such views (fisheye views) might be useful for the computer display of large information structures like programs, data bases, online text, etc. This paper explores fisheye views presenting, in turn, naturalistic studies, a general formalism, a specific instantiation, a resulting computer program, example displays and an evaluation.},
 url = {http://doi.acm.org/10.1145/22339.22342},
 doi = {http://doi.acm.org/10.1145/22339.22342},
 acmid = {22342},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Furnas:1986:GeneralizedFisheyeViews,
 author = {Furnas, G. W.},
 title = {Generalized fisheye views},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 series = {CHI '86},
 year = {1986},
 isbn = {0-89791-180-6},
 location = {Boston, Massachusetts, United States},
 pages = {16--23},
 numpages = {8},
 abstract={In many contexts, humans often represent their own neighborhood in great detail, yet only major landmarks further away. This suggests that such views (fisheye views) might be useful for the computer display of large information structures like programs, data bases, online text, etc. This paper explores fisheye views presenting, in turn, naturalistic studies, a general formalism, a specific instantiation, a resulting computer program, example displays and an evaluation.},
 url = {http://doi.acm.org/10.1145/22627.22342},
 doi = {http://doi.acm.org/10.1145/22627.22342},
 acmid = {22342},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@article{Ciccarelli:1990:BrowsingSchematics,
author = {Ciccarelli, E and Nardi, B},
title = "Browsing schematics: Query-filtered graphs with context nodes",
journal = "Expert Systems with Applications",
volume = "1",
number = "1",
pages = "88 - 88",
year = "1990",
note = "",
issn = "0957-4174",
doi = "DOI: 10.1016/0957-4174(90)90083-7",
url = "http://www.sciencedirect.com/science/article/B6V03-481BN86-S/2/90639021cfee32ed148f8329eed1c51b",
key = "tagkey199088"
}
@INPROCEEDINGS{Craft:2005:VisualInformationSeekingMantra, 
author={Craft, B. and Cairns, P.}, 
booktitle={Information Visualisation, 2005. Proceedings. Ninth International Conference on},
title={Beyond guidelines: what can we learn from the visual information seeking mantra?}, 
year={2005}, 
month={july}, 
volume={}, 
number={}, 
pages={ 110 - 118}, 
abstract={ The field of information visualization offers little methodological guidance to practitioners who seek to design novel systems. Though many sources describe the foundations of the domain, few discuss practical methods for solving visualization problems. One frequently cited guideline to design is the "Visual information-seeking mantra", proposed by Shneiderman in 1996. Although often used to inform the design of information visualization systems, it is unclear what use this has been for visualization designers. We reviewed the current literature that references the mantra, noting what authors have found useful about it and why they cite it. The results indicate a need for empirical validation of the mantra and for a method, such as design patterns, to inform a holistic approach to visualisation design.}, 
keywords={ design pattern; information visualization; visual information seeking mantra; data visualisation;}, 
doi={10.1109/IV.2005.28}, 
ISSN={1550-6037 }}
@article{Green:1996:UsabilityAnalysisOfVisualProgrammingEnvironments,
title = {Usability Analysis of Visual Programming Environments: A Cognitive Dimensions Framework},
journal = {Journal of Visual Languages and Computing},
volume = {7},
number = {2},
pages = {131-174},
year = {1996},
issn = {1045-926X},
doi = {DOI: 10.1006/jvlc.1996.0009},
url = {http://www.sciencedirect.com/science/article/B6WMM-45PVN1Y-1W/2/82bd5bd5a101ae9a40975891ce68e09a},
author = {T. R. G. Green and M. Petre},
abstract = {"The cognitive dimensions framework is a broad-brush evaluation technique for interactive devices and for non-interactive notations. It sets out a small vocabulary of terms designed to capture the cognitively-relevant aspects of structure, and shows how they can be traded off against each other. The purpose of this paper is to propose the framework as an evaluation technique for visual programming environments. We apply it to two commercially-available dataflow languages (with further examples from other systems) and conclude that it is effective and insightful; other HCI-based evaluation techniques focus on different aspects and would make good complements. Insofar as the examples we used are representative, current VPLs are successful in achieving a good [`]closeness of match', but designers need to consider the [`]viscosity ' (resistance to local change) and the [`]secondary notation' (possibility of conveying extra meaning by choice of layout, colour, etc.)."}
}
@inproceedings{Forsell:2010:AnHeuristicSetForEvaluationInInformationVisualization,
 author = {Forsell, Camilla and Johansson, Jimmy},
 title = {An heuristic set for evaluation in information visualization},
 booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
 series = {AVI '10},
 year = {2010},
 isbn = {978-1-4503-0076-6},
 location = {Roma, Italy},
 pages = {199--206},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1842993.1843029},
 doi = {http://doi.acm.org/10.1145/1842993.1843029},
 acmid = {1843029},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Evaluation is a key research challenge within the international Information Visualization (InfoVis) community, and Heuristic Evaluation is one recognized method. Various sets of heuristics have been proposed but there remains no consensus as to which heuristics are most useful for addressing aspects specific to the complex interactive visual displays used in modern InfoVis systems. This paper presents a first effort to empirically determine a new set of such general heuristics tailored for Heuristic Evaluation of common and important usability problems in InfoVis techniques. Participants in the study rated how well a total of 63 heuristics from 6 earlier published heuristic sets could explain a collection of 74 usability problems derived from earlier InfoVis evaluations. The results were used to synthesize 10 heuristics that, as a set, provided the highest explanatory coverage. The paper also stresses the challenges for future research to validate and further improve upon this set.},
 keywords = {heuristic evaluation, heuristics, information visualization},
} 
@inproceedings{Isenberg:2008:GroundedEvaluationOfInformationVisualizations,
 author = {Isenberg, Petra and Zuk, Torre and Collins, Christopher and Carpendale, Sheelagh},
 title = {Grounded evaluation of information visualizations},
 booktitle = {Proceedings of the 2008 conference on BEyond time and errors: novel evaLuation methods for Information Visualization},
 series = {BELIV '08},
 year = {2008},
 isbn = {978-1-60558-016-6},
 location = {Florence, Italy},
 pages = {6:1--6:8},
 articleno = {6},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1377966.1377974},
 doi = {http://doi.acm.org/10.1145/1377966.1377974},
 acmid = {1377974},
 publisher = {ACM},
 abstract={We introduce grounded evaluation as a process that attempts to ensure that the evaluation of an information visualization tool is situated within the context of its intended use. We discuss the process and scope of grounded evaluation in general, and then describe how qualitative inquiry may be a beneficial approach as part of this process. We advocate for increased attention to the field of qualitative inquiry early in the information visualization development life cycle, as it tries to achieve a richer understanding by using a more holistic approach considering the interplay between factors that influence visualizations, their development, and their use. We present three case studies in which we successfully used observational techniques to inform our understanding of the visual analytics process in groups, medical diagnostic reasoning, and visualization use among computational linguists.},
 address = {New York, NY, USA},
 keywords = {evaluation, information visualization},
}
@inproceedings{Shneiderman:1997:DirectManipulation,
 author = {Shneiderman, Ben},
 title = {Direct manipulation for comprehensible, predictable and controllable user interfaces},
 booktitle = {Proceedings of the 2nd international conference on Intelligent user interfaces},
 series = {IUI '97},
 year = {1997},
 isbn = {0-89791-839-8},
 location = {Orlando, Florida, United States},
 pages = {33--39},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/238218.238281},
 doi = {http://doi.acm.org/10.1145/238218.238281},
 acmid = {238281},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {agents, direct manipulation, user interface},
} 
@inproceedings{Nielsen:1994:EnhancingExplanatoryPowerUsabilityHeuristics,
 author = {Nielsen, Jakob},
 title = {Enhancing the explanatory power of usability heuristics},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems: celebrating interdependence},
 series = {CHI '94},
 year = {1994},
 isbn = {0-89791-650-6},
 location = {Boston, Massachusetts, United States},
 pages = {152--158},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/191666.191729},
 doi = {http://doi.acm.org/10.1145/191666.191729},
 acmid = {191729},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {heuristic evaluation, usability problems},
} 
@MISC{Halverson:2002:ActivityTheory,
    author = {Christine A. Halverson},
    title = {Activity Theory and Distributed Cognition: Or What Does CSCW Need to DO with Theories?. Computer Supported Cooperative Work (CSCW},
    year = {2002}
}
@Misc{HistoryMapsCartography,
  title =    {Brief History of Maps and Cartography},
  howpublished = {\url{http://academic.emporia.edu/aberjame/map/h_map/h_map.htm}},
  month =    {April},
  year =     {2011}}
@Misc{HistoryOfWriting,
  title = 	 {History of writing},
  howpublished = {\url{http://en.wikipedia.org/wiki/history_of_writing}},
  month = 	 {April},
  year = 	 {2011}}
@article{Endsley:2000:SituationAwarenessAircraftMaintenance,
title = "Situation awareness in aircraft maintenance teams",
journal = "International Journal of Industrial Ergonomics",
volume = "26",
number = "2",
pages = "301 - 325",
year = "2000",
note = "",
issn = "0169-8141",
doi = "DOI: 10.1016/S0169-8141(99)00073-6",
url = "http://www.sciencedirect.com/science/article/B6V31-40PGW5B-D/2/fe07029af8e949a13d7bdbdbd2b17b46",
author = "Mica R. Endsley and Michelle M. Robertson",
keywords = "Situation awareness",
keywords = "Teams",
keywords = "Maintenance",
keywords = "Training",
keywords = "Error",
abstract = "
Research was conducted at a major airline to investigate factors related to situation awareness in aviation maintenance teams. Situation awareness has been found to be critical to performance and error prevention in many environments. Its role in the maintenance domain for the performance of both individuals and teams is discussed. Situation awareness requirements for aviation maintenance were determined as well as the technologies and personnel resources used to achieve situation awareness. Barriers and problems for situation awareness both across and within teams involved in aviation maintenance were revealed. Based on this analysis, recommendations for the development of a training program to improve situation awareness in aircraft maintenance at the individual and team level are presented.
Relevance to industry
The importance of situation awareness for preventing errors in maintenance is discussed as well as factors that contribute to problems with situation awareness across multiple teams. Specific recommendations for improving situation awareness through organization and system design and through training are made that are applicable to a wide variety of industrial settings."
}
@INPROCEEDINGS{Endsley:1988:SituationAwarenessGlobalAssessment , 
author={Endsley, M.R.}, 
booktitle={Aerospace and Electronics Conference, 1988. NAECON 1988., Proceedings of the IEEE 1988 National}, 
title={Situation awareness global assessment technique (SAGAT)}, 
year={1988}, 
month={may}, 
volume={}, 
number={}, 
pages={789 -795 vol.3}, 
abstract={Pilot-vehicle interface designs must be driven by the gaol of establishing and maintaining high pilot situation awareness. The situation-awareness global assessment technique (SAGAT), developed to assist in this process by providing an objective measure of pilot's situation awareness with any given aircraft design, is described. SAGAT is considered to represent a substantial improvement in the evaluation of pilot-vehicle interface designs, facilitating the development of cockpits which assist the pilot in surviving combat. A formal definition of situation awareness is presented a description of the SAGAT methology and a discussion of its validation}, 
keywords={SAGAT methology;aircraft design;cockpits;pilot-vehicle interface designs;situation-awareness global assessment technique;aircraft instrumentation;human factors;military systems;}, 
doi={10.1109/NAECON.1988.195097}, 
ISSN={},}
@article{Endsley:1988:DesignEvaluationSituationAwarenessEnhancement,
author = {M. R. Endsley},
title = {Design and evaluation for situation awareness enhancement},
year = {1988},
masid = {1298845}
}
@article{Eppler:2004:FacilitatingKnowledgeCommunication,
author = {Martin J. Eppler},
title = {Facilitating Knowledge Communication through Joint Interactive Visualization},
journal = {Journal of Universal Computer Science},
volume = {10},
year = {2004},
pages = {683--690},
masid = {1718642}
}
@inproceedings{Suthers:2005:CollaborativeKnowledgeConstruction,
author = {Daniel D. Suthers},
title = {Collaborative Knowledge Construction through Shared Representations},
booktitle = {Hawaii International Conference on System Sciences},
year = {2005},
doi = {10.1109/HICSS.2005.151},
abstract={This paper is concerned with the question of how activity mediated by shared representations-notations that are manipulated by more than one person during a collaborative task-might constitute knowledge construction activity. The paper begins with a brief review of theoretical perspectives on how representations mediate collaborative knowledge construction, to identify the kinds of events we would look for as evidence of knowledge construction in via a representational medium. Then the paper draws on data from a prior study in which participants collaborated via a graphical representation as well as a verbal "chat" tool, to identify instances of such events and illustrate ways in which the activity of two individuals can be coupled and joined into a larger cognitive (and sometimes knowledge construction) activity distributed across the persons and representations they are manipulating.},
masid = {1826312}}
@inproceedings{Erickson:2011:SynchronousInteractionAmongHundreds,
 author = {Erickson, Thomas and Shami, N. Sadat and Kellogg, Wendy A. and Levine, David W.},
 title = {Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {503--512},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979013},
 doi = {http://doi.acm.org/10.1145/1978942.1979013},
 acmid = {1979013},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper presents the first in-depth evaluation of a large multi-format virtual conference. The conference took place in an avatar-based 3D virtual world with spatialized audio, and had keynote, poster and social sessions. We studied it by drawing on logs, a survey and interviews with 30 participants. We develop a model - Coalescence, Focused Interaction, Remixing (CoFIRe) -- of large synchronous interactions, and use it to discuss how the technology supported, or failed to support, the interactions that are the raison d'etre of conferences. We conclude by discussing the prospects for such large virtual gatherings.},
 keywords = {CMC, CVE, collaborative virtual environment, second life, spatialized audio, synchronous interaction, virtual conference, virtual world},
} 
@inproceedings{Deckers:2011:DesigningForPerceptualCrossingToImproveUserInvolvement,
 author = {Deckers, Eva and Wensveen, Stephan and Ahn, Rene and Overbeeke, Kees},
 title = {Designing for perceptual crossing to improve user involvement},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1929--1938},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979222},
 doi = {http://doi.acm.org/10.1145/1978942.1979222},
 acmid = {1979222},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In this paper we describe our research on how to design for perceptive activity in artifacts in order for perceptual crossing between subject and artifact to happen. We base our research on the phenomenology of perception [19] and on ecological psychology [10]. Perceptual crossing is believed to be essential to share perception and thereby to feel involved in the situation [5,15]. We propose a theoretical model in which perceptive connections between user, artifact and event are presented. We designed an artifact to function as physical hypotheses [9] and show the design relevance of the model. In an experiment we investigate how the user's feeling of involvement is influenced in relation to differentiations of the proposed theoretical model. The results of our experiment show that indeed perceptual crossing between user and artifact influences the user's feeling of involvement with the artifact in their common space. We conclude with describing several design notions important for designing for perceptive activity in artifacts.},
 keywords = {designing for perceptual crossing, phenomenology, research through design},
} 
@inproceedings{Moeller:2011:ZeroTouch:AZeroThicknessOpticalMultitouchForceField,
 author = {Moeller, Jon and Kerne, Andruid and Damaraju, Sashikanth},
 title = {ZeroTouch: a zero-thickness optical multi-touch force field},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {1165--1170},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1979742.1979710},
 doi = {http://doi.acm.org/10.1145/1979742.1979710},
 acmid = {1979710},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We present zero-thickness optical multi-touch sensing, a technique that simplifies sensordisplay integration, and enables new forms of interaction not previously possible with other multi-touch sensing techniques. Using low-cost modulated infrared sensors to quickly determine the visual hull of an interactive area, we enable robust real-time sensing of fingers and hands, even in the presence of strong ambient lighting. Our technology allows for 20+ fingers to be detected, many more than through prior visual hull techniques, and our use of wide-angle optoelectonics allows for excellent touch resolution, even in the corners of the sensor. With the ability to track objects in free space, as well as its use as a traditional multi-touch sensor, ZeroTouch opens up a new world of interaction possibilities.},
 keywords = {input device, multi-touch, sensor, visual hull, zerotouch},
} 
@inproceedings{Moeller:2011:intangibleCanvas:FreeAirFingerPaintingOnAProjectedCanvas,
 author = {Moeller, Jon and Lupfer, Nic and Hamilton, Bill and Lin, Haiqiao and Kerne, Andruid},
 title = {intangibleCanvas: free-air finger painting on a projected canvas},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {1615--1620},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1979742.1979817},
 doi = {http://doi.acm.org/10.1145/1979742.1979817},
 acmid = {1979817},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={With the advent of new sensing technologies, precision free-air interaction is becoming viable as a contender for the next generation of expressive, embodied interaction modalities. ZeroTouch [5], a novel multi-touch sensor that allows for free-air multi-finger, multi-object sensing, is one example of this next generation of free-air interfaces. We develop its use in a digitally-projected finger painting application, placing the see-through multitouch sensor in direct line-of-sight between an artist and a remote canvas. This allows the artist to reach through the sensor and paint on the intangibleCanvas as if it were directly in front of them. An iPad is employed as a multimodal workspace for color selection. We evaluate the system through an informal walk-up-and-play installation and comparative study, developing implications for interaction design using this type of precision free-air interface.},
 keywords = {artistic composition, embodiment, free-air interaction, multi-touch, multimodal interaction},
} 
@inproceedings{Toups:2011:ZeroFidelitySimulationOfFireEmergencyResponse:ImprovingTeamCoordinationLearning,
 author = {Toups, Zachary O. and Kerne, Andruid and Hamilton, William A. and Shahzad, Nabeel},
 title = {Zero-fidelity simulation of fire emergency response: improving team coordination learning},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1959--1968},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979226},
 doi = {http://doi.acm.org/10.1145/1978942.1979226},
 acmid = {1979226},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Fire emergency responders rely on team coordination to survive and succeed in high-stress environments, but traditional education does not directly teach these essential skills. Prior simulations seek the highest possible fidelity, employing resources to capture concrete characteristics of operating environments. We take a different tack, hypothesizing that a zero-fidelity approach, focusing on human-centered aspects of work practice, will improve team coordination learning. Such an approach promotes simulation focus by developing an alternative environment that stimulates participants to engage in distributed cognition. The costs of simulation development are reduced.

To supplement preparation for burn training exercises, 28 fire emergency response students played the Teaching Team Coordination game (T2eC), a zero-fidelity simulation of the distributed cognition of fire emergency response work practice. To test our hypothesis, we develop quantitative evaluation methods for impact on team coordination learning through measures of communication efficiency and cooperative activity. Results show that participants improve cooperation, become more efficient communicators, differentiate team roles through communication, and leverage multiple communication modalities. Given the context of the study amidst the educational process, qualitative data from the students and their expert instructor supports the ecological validity of the contribution of the T2eC zero-fidelity simulation to fire emergency response education.},
 keywords = {distributed cognition, education, emergency response, games, implicit coordination, zero-fidelity simulation},
} 
@inproceedings{Gallud:2011:DistributedUserInterfaces,
 author = {Gallud, Jose A. and Tesoriero, Ricardo and Vanderdonckt, Jean and Lozano, Mar\'{\i}a and Penichet, Victor and Botella, Federico},
 title = {Distributed user interfaces},
 booktitle = {PART 2 ----------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 location = {Vancouver, BC, Canada},
 pages = {2429--2432},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979482.1979576},
 doi = {http://doi.acm.org/10.1145/1979482.1979576},
 acmid = {1979576},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This document exposes the most relevant issues regarding the development of Distributed User Interfaces (DUIs) to present the specific features that are not covered by traditional development processes. A transversal approach to tackle these new aspects is also proposed. Therefore, the goal of this workshop is to promote the discussion about the emerging topic of distributed user interfaces, answering a set of key questions: what, when, how, why distribute a user interface among different devices.},
 keywords = {conceptual framework, distributed user interfaces, pervasive environment},
} 
@inproceedings{Gallud:2011:DUI:1979742.1979576,
 author = {Gallud, Jose A. and Tesoriero, Ricardo and Vanderdonckt, Jean and Lozano, Mar\'{\i}a and Penichet, Victor and Botella, Federico},
 title = {Distributed user interfaces},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {2429--2432},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979576},
 doi = {http://doi.acm.org/10.1145/1979742.1979576},
 acmid = {1979576},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This document exposes the most relevant issues regarding the development of Distributed User Interfaces (DUIs) to present the specific features that are not covered by traditional development processes. A transversal approach to tackle these new aspects is also proposed. Therefore, the goal of this workshop is to promote the discussion about the emerging topic of distributed user interfaces, answering a set of key questions: what, when, how, why distribute a user interface among different devices.},
 keywords = {conceptual framework, distributed user interfaces, pervasive environment},
} 
@inproceedings{Deterding:2011:GamificationUsingGmeDesignElementsInNonGamingContexts,
 author = {Deterding, Sebastian and Sicart, Miguel and Nacke, Lennart and O'Hara, Kenton and Dixon, Dan},
 title = {Gamification. using game-design elements in non-gaming contexts},
 booktitle = {PART 2 ----------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 location = {Vancouver, BC, Canada},
 pages = {2425--2428},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979482.1979575},
 doi = {http://doi.acm.org/10.1145/1979482.1979575},
 acmid = {1979575},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={"Gamification" is an informal umbrella term for the use of video game elements in non-gaming systems to improve user experience (UX) and user engagement. The recent introduction of 'gamified' applications to large audiences promises new additions to the existing rich and diverse research on the heuristics, design patterns and dynamics of games and the positive UX they provide. However, what is lacking for a next step forward is the integration of this precise diversity of research endeavors. Therefore, this workshop brings together practitioners and researchers to develop a shared understanding of existing approaches and findings around the gamification of information systems, and identify key synergies, opportunities, and questions for future research.},
 keywords = {design patterns, funology, game design, games with a purpose, gamification, motivational affordances, persuasive technology},
} 
@inproceedings{Deterding:2011:GUG:1979742.1979575,
 author = {Deterding, Sebastian and Sicart, Miguel and Nacke, Lennart and O'Hara, Kenton and Dixon, Dan},
 title = {Gamification. using game-design elements in non-gaming contexts},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {2425--2428},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979575},
 doi = {http://doi.acm.org/10.1145/1979742.1979575},
 acmid = {1979575},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={"Gamification" is an informal umbrella term for the use of video game elements in non-gaming systems to improve user experience (UX) and user engagement. The recent introduction of 'gamified' applications to large audiences promises new additions to the existing rich and diverse research on the heuristics, design patterns and dynamics of games and the positive UX they provide. However, what is lacking for a next step forward is the integration of this precise diversity of research endeavors. Therefore, this workshop brings together practitioners and researchers to develop a shared understanding of existing approaches and findings around the gamification of information systems, and identify key synergies, opportunities, and questions for future research.},
 keywords = {design patterns, funology, game design, games with a purpose, gamification, motivational affordances, persuasive technology},
} 
@inproceedings{Steinicke:2011:TouchingThe3rdDimension,
 author = {Steinicke, Frank and Benko, Hrvoje and Daiber, Florian and Keefe, Daniel and de la Rivi\`{e}re, Jean-Baptiste},
 title = {Touching the 3rd dimension (T3D)},
 booktitle = {PART 2 ----------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 location = {Vancouver, BC, Canada},
 pages = {161--164},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979482.1979525},
 doi = {http://doi.acm.org/10.1145/1979482.1979525},
 acmid = {1979525},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In recent years interactive visualization of 3D data has become increasingly important and widespread due to the requirements of several application areas. However, current user interfaces often lack adequate support for 3D interactions: 2D desktop systems are often limited in cases where natural interaction with 3D content is required, and sophisticated 3D user interfaces consisting of stereoscopic projections and tracked input devices are rarely adopted by ordinary users. Touch interaction has received considerable attention for 2D interfaces, and more recently for 3D interfaces. Many touch devices now support multiple degrees of freedom input by capturing multiple 2D contact positions on the surface as well as varying levels of pressure and even depth. There is, therefore, great potential for multi-touch interfaces to provide the traditionally difficult to achieve combination of natural 3D interaction without any instrumentation. When combined with a stereoscopic display of 3D data as well as 3D depth cameras, we believe that multi-touch technology can form the basis for a next generation of intuitive and expressive 3D user interfaces. Several research groups have begun to explore the potential, limitations, and challenges of this and other 3D touch environments, and first commercial systems are already available. The goal of the SIG "Touching the 3rd Dimension (T3D)" is to address the research and industrial challenges involved in exploring the space where the flat digital world of surface computing meets the physical, spatially complex, 3D space in which we live. The meeting will provide a common forum to attract groups of conference attendees who share their visions of the future and recent results in the area of improving 3D interaction and visualization by taking advantage of the strengths of advanced multi-touch computing.},
 keywords = {3D interaction, 3D user interfaces, multi-touch, stereoscopic visualization},
} 
@inproceedings{Steinicke:2011:TD:1979742.1979525,
 author = {Steinicke, Frank and Benko, Hrvoje and Daiber, Florian and Keefe, Daniel and de la Rivi\`{e}re, Jean-Baptiste},
 title = {Touching the 3rd dimension (T3D)},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {161--164},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979525},
 doi = {http://doi.acm.org/10.1145/1979742.1979525},
 acmid = {1979525},
 publisher = {ACM},
 abstract={In recent years interactive visualization of 3D data has become increasingly important and widespread due to the requirements of several application areas. However, current user interfaces often lack adequate support for 3D interactions: 2D desktop systems are often limited in cases where natural interaction with 3D content is required, and sophisticated 3D user interfaces consisting of stereoscopic projections and tracked input devices are rarely adopted by ordinary users. Touch interaction has received considerable attention for 2D interfaces, and more recently for 3D interfaces. Many touch devices now support multiple degrees of freedom input by capturing multiple 2D contact positions on the surface as well as varying levels of pressure and even depth. There is, therefore, great potential for multi-touch interfaces to provide the traditionally difficult to achieve combination of natural 3D interaction without any instrumentation. When combined with a stereoscopic display of 3D data as well as 3D depth cameras, we believe that multi-touch technology can form the basis for a next generation of intuitive and expressive 3D user interfaces. Several research groups have begun to explore the potential, limitations, and challenges of this and other 3D touch environments, and first commercial systems are already available. The goal of the SIG "Touching the 3rd Dimension (T3D)" is to address the research and industrial challenges involved in exploring the space where the flat digital world of surface computing meets the physical, spatially complex, 3D space in which we live. The meeting will provide a common forum to attract groups of conference attendees who share their visions of the future and recent results in the area of improving 3D interaction and visualization by taking advantage of the strengths of advanced multi-touch computing.},
 address = {New York, NY, USA},
 keywords = {3D interaction, 3D user interfaces, multi-touch, stereoscopic visualization},
} 
@inproceedings{Hopmann:2011:NaturalActivationForGestureRecognitionSystems,
 author = {Hopmann, Mathieu and Salamin, Patrick and Chauvin, Nicolas and Vexo, Fr\'{e}d\'{e}ric and Thalmann, Daniel},
 title = {Natural activation for gesture recognition systems},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {173--183},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1979742.1979642},
 doi = {http://doi.acm.org/10.1145/1979742.1979642},
 acmid = {1979642},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Gesture recognition is becoming a popular way of interaction, but still suffers of important drawbacks to be integrated in everyday life devices. One of these drawbacks is the activation of the recognition system -- trigger gesture - which is generally tiring and unnatural. In this paper, we propose two natural solutions to easily activate the gesture interaction. The first one requires a single action from the user: grasping a remote control to start interacting. The second one is completely transparent for the user: the gesture system is only activated when the user's gaze points to the screen, i.e. when s/he is looking at it. Our first evaluation with the 2 proposed solutions plus a default implementation suggests that the gaze estimation activation is efficient enough to remove the need of a trigger gesture in order to activate the recognition system.},
 keywords = {hand gesture, human-computer interface},
}
@inproceedings{Bragdon:2011:ExperimentalAnalysisOfTouchcreenGestureDesignsInMobileEnvironments,
 author = {Bragdon, Andrew and Nelson, Eugene and Li, Yang and Hinckley, Ken},
 title = {Experimental analysis of touch-screen gesture designs in mobile environments},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {403--412},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979000},
 doi = {http://doi.acm.org/10.1145/1978942.1979000},
 acmid = {1979000},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Direct-touch interaction on mobile phones revolves around screens that compete for visual attention with users' real-world tasks and activities. This paper investigates the impact of these situational impairments on touch-screen interaction. We probe several design factors for touch-screen gestures, under various levels of environmental demands on attention, in comparison to the status-quo approach of soft buttons. We find that in the presence of environmental distractions, gestures can offer significant performance gains and reduced attentional load, while performing as well as soft buttons when the user's attention is focused on the phone. In fact, the speed and accuracy of bezel gestures did not appear to be significantly affected by environment, and some gestures could be articulated eyes-free, with one hand. Bezel-initiated gestures offered the fastest performance, and mark-based gestures were the most accurate. Bezel-initiated marks therefore may offer a promising approach for mobile touch-screen interaction that is less demanding of the user's attention.},
 keywords = {evaluation, gestures, mobile phones, performance, touch},
} 
@inproceedings{Junuzovic:2011:WhatDidIMiss:InMeetingReviewUsingMmultimodalAcceleratedInstantReplayAirConferencing,
 author = {Junuzovic, Sasa and Inkpen, Kori and Hegde, Rajesh and Zhang, Zhengyou and Tang, John and Brooks, Christopher},
 title = {What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {513--522},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979014},
 doi = {http://doi.acm.org/10.1145/1978942.1979014},
 acmid = {1979014},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={People sometimes miss small parts of meetings and need to quickly catch up without disrupting the rest of the meeting. We developed an Accelerated Instant Replay (AIR) Conferencing system for videoconferencing that enables users to catch up on missed content while the meeting is ongoing. AIR can replay parts of the conference using four different modalities: audio, video, conversation transcript, and shared workspace. We performed two studies to evaluate the system. The first study explored the benefit of AIR catch-up during a live meeting. The results showed that when the full videoconference was reviewed (i.e., all four modalities) at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live. To better understand the benefit of full review, a follow-up study more closely examined the benefits of each of the individual modalities. The results show that users (a) preferred using audio along with any other modality to using audio alone, (b) were most confident and performed best when audio was reviewed with all other modalities, (c) compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and (d) performed similarly with audio-only and audio with video review.},
 keywords = {audio, cscw, dvr, meetings, review, shared workspace, telepresence, transcript, video, videoconferencing},
} 
@article{O'hara:2011:BlendedInteractionSpacesForDistributedTeamCollaboration,
 author = {O'hara, Kenton and Kjeldskov, Jesper and Paay, Jeni},
 title = {Blended interaction spaces for distributed team collaboration},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {April 2011},
 volume = {18},
 issue = {1},
 month = {May},
 year = {2011},
 issn = {1073-0516},
 pages = {3:1--3:28},
 articleno = {3},
 numpages = {28},
 url = {http://doi.acm.org/10.1145/1959022.1959025},
 doi = {http://doi.acm.org/10.1145/1959022.1959025},
 acmid = {1959025},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In recent years there has been an introduction of sophisticated new video conferencing technologies (e.g., HP Halo, Cisco Telepresence) that have led to enhancements in the collaborative user experience over traditional video conferencing technologies. Traditional video conferencing set-ups often distort the shared spatial properties of action and communication due to screen and camera orientation disparities and other asymmetries. These distortions affect access to the common resources used to mutually organize action and communication. By contrast, new systems, such as Halo, are physically configured to reduce these asymmetries and orientation disparities, thereby minimizing these spatial distortions. By creating appropriate shared spatial geometries, the distributed spaces become blended where the spatial geometries of the local space continue coherently across the distributed boundary into the remote site, providing the illusion of a single unified space. Drawing on theories of embodied action and workplace design we discuss the importance of this geometric blending of space for distributed collaboration and how this is achieved in systems such as Halo. We then extend these arguments to explore the concept of Blended Interaction Spaces: blended spaces in which interactive groupware is incorporated in ways spatially consistent with the physical geometries of the video-mediated set-up. We illustrate this discussion through a system called BISi that introduces interactive horizontal and vertical multipoint surfaces into a blended video-mediated collaboration space. In presenting this system, we highlight some of the particular challenges of creating these systems arising from the spatial consequences of different interaction mechanisms (e.g., direct touch or remote control) and how they affect movement and spatial configuration of people in these spaces.},
 keywords = {Collaboration, media spaces, telepresence},
}
@inproceedings{Paay:2011:BISi:ABlendedInteractionSpace,
 author = {Paay, Jeni and Kjeldskov, Jesper and O'Hara, Kenton},
 title = {BISi: a blended interaction space},
 booktitle = {PART 1 ---------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {185--200},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/1979602.1979644},
 doi = {http://doi.acm.org/10.1145/1979602.1979644},
 acmid = {1979644},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Distributed collaboration has been enhanced in recent years by sophisticated new video conferencing setups like HP Halo and Cisco Telepresence, improving the user experience of distributed meeting situations over traditional video conferencing. The experience created can be described as one of "blending" distributed physical locations into one shared space. Inspired by this trend, we have been exploring the systematic creation of blended spaces for distributed collaboration through the design of appropriate shared spatial geometries. We present early iterations of our design work: the Blended Interaction Space One prototype, BISi, and the lessons learned from its creation.},
 keywords = {blended spaces, collaborative computing, media spaces},
} 
[download]
@inproceedings{Paay:2011:BIB:1979742.1979644,
 author = {Paay, Jeni and Kjeldskov, Jesper and O'Hara, Kenton},
 title = {BISi: a blended interaction space},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {185--200},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/1979742.1979644},
 doi = {http://doi.acm.org/10.1145/1979742.1979644},
 acmid = {1979644},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Distributed collaboration has been enhanced in recent years by sophisticated new video conferencing setups like HP Halo and Cisco Telepresence, improving the user experience of distributed meeting situations over traditional video conferencing. The experience created can be described as one of "blending" distributed physical locations into one shared space. Inspired by this trend, we have been exploring the systematic creation of blended spaces for distributed collaboration through the design of appropriate shared spatial geometries. We present early iterations of our design work: the Blended Interaction Space One prototype, BISi, and the lessons learned from its creation.},
 keywords = {blended spaces, collaborative computing, media spaces},
} 

@inproceedings{Broughton:2009:BeingHere:DesigningForDistributedHandsOnCollaborationInBlendedInteractionSpaces,
 author = {Broughton, Michael and Paay, Jeni and Kjeldskov, Jesper and O'Hara, Kenton and Li, Jane and Phillips, Matthew and Rittenbruch, Markus},
 title = {Being here: designing for distributed hands-on collaboration in blended interaction spaces},
 booktitle = {Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group: Design: Open 24/7},
 series = {OZCHI '09},
 year = {2009},
 isbn = {978-1-60558-854-4},
 location = {Melbourne, Australia},
 pages = {73--80},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1738826.1738839},
 doi = {http://doi.acm.org/10.1145/1738826.1738839},
 acmid = {1738839},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper describes a concept for supporting distributed hands-on collaboration through interaction design for the physical and the digital workspace. The Blended Interaction Spaces concept creates distributed work environments in which collaborating parties all feel that they are present "here" rather than "there". We describe thinking and inspirations behind the Blended Interaction Spaces concept, and summarize findings from fieldwork activities informing our design. We then exemplify the Blended Interaction Spaces concept through a prototype implementation of one of four concepts.},
 keywords = {CSCW, blended interaction spaces, distributed collaboration, hands-on collaboration, video conferencing},
} 
@inproceedings{Jain:2011:TheFutureOfNaturalUserInterfaces,
 author = {Jain, Jhilmil and Lund, Arnold and Wixon, Dennis},
 title = {The future of natural user interfaces},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {211--214},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979527},
 doi = {http://doi.acm.org/10.1145/1979742.1979527},
 acmid = {1979527},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This SIG is a forum to advance an integrated approach to multi-modal Natural User Interfaces. Up until now the research and design of NUI interfaces for various modalities (speech, touch, gesture) has proceeded independently. We propose having an integrated discussion with both academics and practitioners to stimulate the exchange of knowledge about the various modalities and how they might be fruitfully combined, and identifying key areas of future research and design that make the case for multi-modal NUIs. The goal is to not only create a vision of synthetic applications of NUI by connecting researchers but to also discuss ways to make the vision a reality.},
 keywords = {3D, NUI, augmented reality, gesture, multimodal interface, natural user interface, speech, touch},
} 
@inproceedings{Jain:2011:FNU:1979482.1979527,
 author = {Jain, Jhilmil and Lund, Arnold and Wixon, Dennis},
 title = {The future of natural user interfaces},
 booktitle = {PART 2 ----------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 location = {Vancouver, BC, Canada},
 pages = {211--214},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979482.1979527},
 doi = {http://doi.acm.org/10.1145/1979482.1979527},
 acmid = {1979527},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This SIG is a forum to advance an integrated approach to multi-modal Natural User Interfaces. Up until now the research and design of NUI interfaces for various modalities (speech, touch, gesture) has proceeded independently. We propose having an integrated discussion with both academics and practitioners to stimulate the exchange of knowledge about the various modalities and how they might be fruitfully combined, and identifying key areas of future research and design that make the case for multi-modal NUIs. The goal is to not only create a vision of synthetic applications of NUI by connecting researchers but to also discuss ways to make the vision a reality.},
 keywords = {3D, NUI, augmented reality, gesture, multimodal interface, natural user interface, speech, touch},
} 
@inproceedings{Kuhn:2011:UsingTagsToEncourageReflectionAndAnnotationOnDataDuringNomadicInquiry,
 author = {Kuhn, Alex and Cahill, Clara and Quintana, Chris and Schmoll, Shannon},
 title = {Using tags to encourage reflection and annotation on data during nomadic inquiry},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {667--670},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979038},
 doi = {http://doi.acm.org/10.1145/1978942.1979038},
 acmid = {1979038},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Nomadic inquiry may benefit from tagging when used for educational purposes to support reflection and annotation during data collection. To that end we created Zydeco, a mobile system to scaffold learners through the science inquiry process in and out of the classroom, and tested it in a museum with 42 middle school students. Students report that tags encouraged reflection and annotation during data collection, suggesting that tagging can be used to support nomadic inquiry. From this work we present some emerging design recommendations for constructing similar systems.},
 keywords = {learner-centered design, mobile computing, mobile learning, nomadic inquiry, scaffolding, tagging},
} 
@article{Bernstein:2008:PersonalizationViaFriendsourcing,
 author = {Bernstein, Michael S. and Tan, Desney and Smith, Greg and Czerwinski, Mary and Horvitz, Eric},
 title = {Personalization via friendsourcing},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 volume = {17},
 issue = {2},
 month = {May},
 year = {2008},
 issn = {1073-0516},
 pages = {6:1--6:28},
 articleno = {6},
 numpages = {28},
 url = {http://doi.acm.org/10.1145/1746259.1746260},
 doi = {http://doi.acm.org/10.1145/1746259.1746260},
 acmid = {1746260},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={When information is known only to friends in a social network, traditional crowdsourcing mechanisms struggle to motivate a large enough user population and to ensure accuracy of the collected information. We thus introduce friendsourcing, a form of crowdsourcing aimed at collecting accurate information available only to a small, socially-connected group of individuals. Our approach to friendsourcing is to design socially enjoyable interactions that produce the desired information as a side effect.

We focus our analysis around Collabio, a novel social tagging game that we developed to encourage friends to tag one another within an online social network. Collabio encourages friends, family, and colleagues to generate useful information about each other. We describe the design space of incentives in social tagging games and evaluate our choices by a combination of usage log analysis and survey data. Data acquired via Collabio is typically accurate and augments tags that could have been found on Facebook or the Web. To complete the arc from data collection to application, we produce a trio of prototype applications to demonstrate how Collabio tags could be utilized: an aggregate tag cloud visualization, a personalized RSS feed, and a question and answer system. The social data powering these applications enables them to address needs previously difficult to support, such as question answering for topics comprehensible only to a few of a user's friends.},
 keywords = {Social computing, friendsourcing, human computation, social tagging},
} 
@article{Fu:2010:SemanticImitationInSocialTagging,
 author = {Fu, Wai-Tat and Kannampallil, Thomas and Kang, Ruogu and He, Jibo},
 title = {Semantic imitation in social tagging},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {July 2010},
 volume = {17},
 issue = {3},
 month = {July},
 year = {2010},
 issn = {1073-0516},
 pages = {12:1--12:37},
 articleno = {12},
 numpages = {37},
 url = {http://doi.acm.org/10.1145/1806923.1806926},
 doi = {http://doi.acm.org/10.1145/1806923.1806926},
 acmid = {1806926},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We present a semantic imitation model of social tagging and exploratory search based on theories of cognitive science. The model assumes that social tags evoke a spontaneous tag-based topic inference process that primes the semantic interpretation of resource contents during exploratory search, and the semantic priming of existing tags in turn influences future tag choices. The model predicts that (1) users who can see tags created by others tend to create tags that are semantically similar to these existing tags, demonstrating the social influence of tag choices; and (2) users who have similar information goals tend to create tags that are semantically similar, but this effect is mediated by the semantic representation and interpretation of social tags. Results from the experiment comparing tagging behavior between a social group (where participants can see tags created by others) and a nominal group (where participants cannot see tags created by others) confirmed these predictions. The current results highlight the critical role of human semantic representations and interpretation processes in the analysis of large-scale social information systems. The model implies that analysis at both the individual and social levels are important for understanding the active, dynamic processes between human knowledge structures and external folksonomies. Implications on how social tagging systems can facilitate exploratory search, interactive information retrievals, knowledge exchange, and other higher-level cognitive and learning activities are discussed.},
 keywords = {Semantic imitation, cognitive models, human information processing, multilevel models, semantic representations, social tagging},
} 
@inproceedings{Marathe:2011:WhatDrivesCustomizationControlOrIdentity,
 author = {Marathe, Sampada and Sundar, S. Shyam},
 title = {What drives customization?: control or identity?},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {781--790},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979056},
 doi = {http://doi.acm.org/10.1145/1978942.1979056},
 acmid = {1979056},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Customization - an attribute that lets users take control and make changes to the presentation and functionality of the interface - is becoming a hallmark of today's interactive media devices. What do users experience when they change interface aspects like fonts and colors, skins on mobile phones, speed dial numbers, privacy settings on social networks and different command menus in software? Do they feel in control? Do they see the customized interface as a reflection of who they are? More importantly, is the feeling of being in control a major driver of usage, or does sense of identity - a personal connection with the interface - prove more vital? This paper discusses the psychology of customization, reports an empirical user study designed to explore the relationship between customization, sense of control, and sense of identity, and outlines implications for design of customizable interfaces based on the findings.},
 keywords = {customization, sense of control, sense of identity, user experience},
} 
@inproceedings{Wigdor:2011:RockandRails:ExtendingMultitouchInteractionsWithShapeGesturesToEnablePreciseSpatialManipulations,
 author = {Wigdor, Daniel and Benko, Hrvoje and Pella, John and Lombardo, Jarrod and Williams, Sarah},
 title = {Rock \&\#38; rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1581--1590},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979173},
 doi = {http://doi.acm.org/10.1145/1978942.1979173},
 acmid = {1979173},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Direct touch manipulations enable the user to interact with the on-screen content in a direct and easy manner closely mimicking the spatial manipulations in the physical world. However, they also suffer from well-known issues of precision, occlusion and an inability to isolate different degrees of freedom in spatial manipulations. We present a set of interactions, called Rock & Rails, that augment existing direct touch manipulations with shape-based gestures, thus providing on-demand gain control, occlusion avoidance, and separation of constraints in 2D manipulation tasks. Using shape gestures in combination with direct-manipulations allows us to do this without ambiguity in detection and without resorting to manipulation handles, which break the direct manipulation paradigm. Our set of interactions were evaluated by 8 expert graphic designers and were found to be easy to learn and master, as well as effective in accomplishing a precise graphical layout task.},
 keywords = {fluid, interactive surfaces, precise multi-touch interactions, separation of constraints, shape gestures},
} 
@inproceedings{Chiu:2011:MultitouchDocumentFolding:GestureModelsFoldDirectionsAndSymmetries,
 author = {Chiu, Patrick and Liao, Chunyuan and Chen, Francine},
 title = {Multi-touch document folding: gesture models, fold directions and symmetries},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1591--1600},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979174},
 doi = {http://doi.acm.org/10.1145/1978942.1979174},
 acmid = {1979174},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections. To enable richer interaction, we explore the design space of multi-touch document folding. We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures. We categorize gesture models along the characteristics of Symmetric/Asymmetric and Serial/Parallel, which yields three gesture models. We built a prototype document workspace application that integrates folding and standard gestures, and a system for testing the gesture models. A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance when folding a document to a specific shape. Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets.},
 keywords = {document visualization, gesture input, multi-touch screens},
} 
@inproceedings{Kaser:2011:FingerGlass:EfficientMultiscaleInteractionOnMultitouchScreens,
 author = {K\"{a}ser, Dominik P. and Agrawala, Maneesh and Pauly, Mark},
 title = {FingerGlass: efficient multiscale interaction on multitouch screens},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1601--1610},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979175},
 doi = {http://doi.acm.org/10.1145/1978942.1979175},
 acmid = {1979175},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Many tasks in graphical user interfaces require users to interact with elements at various levels of precision. We present FingerGlass, a bimanual technique designed to improve the precision of graphical tasks on multitouch screens. It enables users to quickly navigate to different locations and across multiple scales of a scene using a single hand. The other hand can simultaneously interact with objects in the scene. Unlike traditional pan-zoom interfaces, FingerGlass retains contextual information during the interaction. We evaluated our technique in the context of precise object selection and translation and found that FingerGlass significantly outperforms three state-of-the-art baseline techniques in both objective and subjective measurements: users acquired and translated targets more than 50% faster than with the second-best technique in our experiment.},
 keywords = {bimanual, fat finger problem, multiscale interaction, navigation, object translation, precise selection, touch screens},
} 
@inproceedings{Sun:2011:AnInteractiveMultitouchSketchingInterfaceForDiffusionCurves,
 author = {Sun, Qian and Fu, Chi-Wing and He, Ying},
 title = {An interactive multi-touch sketching interface for diffusion curves},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1611--1614},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979176},
 doi = {http://doi.acm.org/10.1145/1978942.1979176},
 acmid = {1979176},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Diffusion curves are effective 2D vector-graphics primitives, for creating smoothly-shaded drawings with rich colors and unique styles. Conventional drawing systems for diffusion curves often require users to successively layout curve geometry and then specify colors, which is rather tedious for complex drawings. This paper proposes a novel multi-touch sketching interface for efficient design of 2D vector graphics with diffusion curves. In sharp contrast to previous interfaces, we develop a family of multi-touch gestures, allowing users to simultaneously sketch multiple diffusion curves and also to interactively edit and tune curve geometry and colors. Our experiments show that this not only brings novel painting experience to users but also provides a practical and effective tool for vector graphics design, useful for styles like silk painting, Disney cartoon, art poster, and photo-realistic effects. Lastly, we conduct a user study to explore the interface's intuitive and efficient drawing capability with both professional 2D artists and novice users.},
 keywords = {diffusion curve, multi-touch interactions, sketching, vector graphics},
} 
@inproceedings{Frisch:2011:GridsAndGuides:MultiouchLayoutAndAlignmentTools,
 author = {Frisch, Mathias and Kleinau, Sebastian and Langner, Ricardo and Dachselt, Raimund},
 title = {Grids \&\#38; guides: multi-touch layout and alignment tools},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1615--1618},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979177},
 doi = {http://doi.acm.org/10.1145/1978942.1979177},
 acmid = {1979177},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Precise alignment of graphical objects and the creation of accurate layouts are crucial activities in many applications, such as graphics design tools, presentation software or graph editors. Surface computing is very promising for these application domains but not fully explored yet. In this paper we contribute two tools which support layout tasks on interactive displays: interactive grids and multi-touch alignment guides. Both tools allow the precise positioning of graphical objects in a flexible and fluent way by multi-touch input. Direct bimanual interaction and physical metaphors are applied to arrange objects along straight lines and curves. A formative user evaluation showed promising results with regard to a productive and easy use of the tools.},
 keywords = {interactive grids, layout techniques, manual diagram layout, multi-touch alignment guides, snap-dragging},
} 
@inproceedings{Aragon:2011:CollaborativeCreativity:AcomplexSystemsModelWithDistributedAffect,
 author = {Aragon, Cecilia R. and Williams, Alison},
 title = {Collaborative creativity: a complex systems model with distributed affect},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {1875--1884},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979214},
 doi = {http://doi.acm.org/10.1145/1978942.1979214},
 acmid = {1979214},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={The study of creativity has received significant attention over the past century, with a recent increase in interest in collaborative, distributed creativity. We posit that creativity in distributed groups is fostered by software interfaces that specifically enable socio-emotional or affective communication. However, previous work on creativity and affect has primarily focused on the individual, while group creativity research has concentrated more on cognition rather than affect. In this paper we propose a new model for creativity in distributed groups, based on the theory of groups as complex systems, that includes affect as well as cognition and that explicitly calls out the interface between individuals as a key parameter of the model. We describe the model, the four stages of collaborative creativity and the causal dynamics in each stage, and demonstrate how affect and interface can facilitate the generation, selection, and amplification of ideas in the various stages of collaborative creativity. We then validate our model with data from three field sites. The data was collected from longitudinal studies of two distributed groups involved in producing creative products--astrophysicists studying supernovae and the expansion rate of the universe and children creating multimedia programming projects online-"-and interviews with staff in a multinational engineering company.},
 keywords = {collaborative creativity, computer-mediated communication, creativity model, distributed affect, distributed groups},
} 
@inproceedings{Yoo:2011:3DRemoteInterfaceForSmartDisplays,
 author = {Yoo, ByungIn and Han, Jae-Joon and Choi, Changkyu and Ryu, Hee-seob and Park, Du Sik and Kim, Chang Yeong},
 title = {3D remote interface for smart displays},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {551--560},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1979742.1979626},
 doi = {http://doi.acm.org/10.1145/1979742.1979626},
 acmid = {1979626},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={The paper presents a novel user interface combining bare hands and the line of sight (LoS) by using a depth camera from far distance without any handheld devices; as well as a 3D GUI providing both stereoscopy and motion parallax for smart displays. The proposed user interface provides a precise and convenient manipulation which is applicable to browsing thousands of channels andor media files. Especially, the combined interaction methods of the two modalities achieve 120(x)  70(y)  5(z) manipulation resolution. And then various user tasks were performed so as to assess the proposed user interface.},
 keywords = {3D remote interface, bare hands, depth camera, line of sight, motion parallax, smart display, stereoscopy},
} 
@inproceedings{Matthews:2011:CollaborationPersonas:AnewApproachToDesigningWorkplaceCollaborationTools,
 author = {Matthews, Tara and Whittaker, Steve and Moran, Thomas and Yuen, Sandra},
 title = {Collaboration personas: a new approach to designing workplace collaboration tools},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2247--2256},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979272},
 doi = {http://doi.acm.org/10.1145/1978942.1979272},
 acmid = {1979272},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={The success of social computing has generated a host of workplace collaboration tools. However, adoption of these tools by entire groups is a major problem. One reason for the adoption problem is a lack of methods for considering collaborative groups in technology design. Even when designing collaboration tools, designers often employ methods that focus on individuals. This leads to tools that are not well targeted at the groups who will use them. To solve this problem, we propose the notion of collaboration personas, which are empirically derived descriptions of hypothetical groups, including details that inform the design of collaboration tools. Collaboration personas differ from individual personas in having (1) multiple, inter-related individuals playing specific roles; (2) a focus on collective goals and elaboration of individual goals that affect the collective goal; and (3) new attributes that characterize collaborative aspects of the group's work. We contrast collaboration personas with other design approaches and provide examples of how they can be used to design new collaborative tools that better meet the needs of typical groups.},
 keywords = {collaboration, design tools, office, personas, workplace},
} 
@inproceedings{Bakke:2011:ASpreadsheetBasedUserInterfaceForManagingPluralRelationshipsInStructuredData,
 author = {Bakke, Eirik and Karger, David and Miller, Rob},
 title = {A spreadsheet-based user interface for managing plural relationships in structured data},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2541--2550},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979313},
 doi = {http://doi.acm.org/10.1145/1978942.1979313},
 acmid = {1979313},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={A key feature of relational database applications is managing \emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40% faster on average.},
 keywords = {databases, foreign key relationships, hierarchical views, one-to-many relationships, spreadsheets},
} 
@inproceedings{Findlater:2011:TypingOnFlatGlass,
 author = {Findlater, Leah and Wobbrock, Jacob O. and Wigdor, Daniel},
 title = {Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2453--2462},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979301},
 doi = {http://doi.acm.org/10.1145/1978942.1979301},
 acmid = {1979301},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Touch screen surfaces large enough for ten-finger input have become increasingly popular, yet typing on touch screens pales in comparison to physical keyboards. We examine typing patterns that emerge when expert users of physical keyboards touch-type on a flat surface. Our aim is to inform future designs of touch screen keyboards, with the ultimate goal of supporting touch-typing with limited tactile feedback. To study the issues inherent to flat-glass typing, we asked 20 expert typists to enter text under three conditions: (1) with no visual keyboard and no feedback on input errors, then (2) with and (3) without a visual keyboard, but with some feedback. We analyzed touch contact points and hand contours, looking at attributes such as natural finger positioning, the spread of hits among individual keys, and the pattern of non-finger touches. We also show that expert typists exhibit spatially consistent key press distributions within an individual, which provides evidence that eyes-free touch-typing may be possible on touch surfaces and points to the role of personalization in such a solution. We conclude with implications for design.},
 keywords = {multi-touch input, tabletop computing, touch-typing, user study},
} 
@inproceedings{Abdulin:2011:UsingTheKeystrokeLevelModelForDesigningUserInterfaceOnMidSizedTouchscreens,
 author = {Abdulin, Evgeniy},
 title = {Using the keystroke-level model for designing user interface on middle-sized touch screens},
 booktitle = {PART 1 ---------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {673--686},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1979602.1979667},
 doi = {http://doi.acm.org/10.1145/1979602.1979667},
 acmid = {1979667},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={The Keystroke-Level Model was developed to predict accurately task execution time for mouse-and-keyboard systems. Middle-sized touch screens are becoming much more popular so it is important to determine whether KLM can provide useful predictions for these interfaces as well. The KLMs were created using special software CogTool for three touch screen interfaces for integrated control systems and were compared to experimental data. The results showed that the KLM prediction error for middle-sized touch screens reached less than 5%. This conclusion is that KLM has acceptable accuracy level in this environment for making predictions for the task execution times.},
 keywords = {cognitive modeling, keystroke-level model},
} 
@inproceedings{Abdulin:2011:UKM:1979742.1979667,
 author = {Abdulin, Evgeniy},
 title = {Using the keystroke-level model for designing user interface on middle-sized touch screens},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {673--686},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1979742.1979667},
 doi = {http://doi.acm.org/10.1145/1979742.1979667},
 acmid = {1979667},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={The Keystroke-Level Model was developed to predict accurately task execution time for mouse-and-keyboard systems. Middle-sized touch screens are becoming much more popular so it is important to determine whether KLM can provide useful predictions for these interfaces as well. The KLMs were created using special software CogTool for three touch screen interfaces for integrated control systems and were compared to experimental data. The results showed that the KLM prediction error for middle-sized touch screens reached less than 5%. This conclusion is that KLM has acceptable accuracy level in this environment for making predictions for the task execution times.},
 keywords = {cognitive modeling, keystroke-level model},
} 
@inproceedings{Holz:2011:UnderstandingTouch,
 author = {Holz, Christian and Baudisch, Patrick},
 title = {Understanding touch},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2501--2510},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979308},
 doi = {http://doi.acm.org/10.1145/1978942.1979308},
 acmid = {1979308},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Current touch devices, such as capacitive touchscreens are based on the implicit assumption that users acquire targets with the center of the contact area between finger and device. Findings from our previous work indicate, however, that such devices are subject to systematic error offsets. This suggests that the underlying assumption is most likely wrong. In this paper, we therefore revisit this assumption. In a series of three user studies, we find evidence that the features that users align with the target are visual features. These features are located on the top of the user's fingers, not at the bottom, as assumed by traditional devices. We present the projected center model, under which error offsets drop to 1.6mm, compared to 4mm for the traditional model. This suggests that the new model is indeed a good approximation of how users conceptualize touch input. The primary contribution of this paper is to help understand touch-one of the key input technologies in human-computer interaction. At the same time, our findings inform the design of future touch input technology. They explain the inaccuracy of traditional touch devices as a -Sparallax- artifact between user control based on the top of the finger and sensing based on the bottom side of the finger. We conclude that certain camera-based sensing technologies can inherently be more accurate than contact area-based sensing.},
 keywords = {experiment, generalized perceived input point model, targeting, touch input},
} 
@inproceedings{Bi:2011:MagicDesk:BringingMultitouchSurfacesIntoDesktopWork,
 author = {Bi, Xiaojun and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
 title = {Magic desk: bringing multi-touch surfaces into desktop work},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2511--2520},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979309},
 doi = {http://doi.acm.org/10.1145/1978942.1979309},
 acmid = {1979309},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Despite the prominence of multi-touch technologies, there has been little work investigating its integration into the desktop environment. Bringing multi-touch into desktop computing would give users an additional input channel to leverage, enriching the current interaction paradigm dominated by a mouse and keyboard. We provide two main contributions in this domain. First, we describe the results from a study we performed, which systematically evaluates the various potential regions within the traditional desktop configuration that could become multi-touch enabled. The study sheds light on good or bad regions for multi-touch, and also the type of input most appropriate for each of these regions. Second, guided by the results from our study, we explore the design space of multi-touch-integrated desktop experiences. A set of new interaction techniques are coherently integrated into a desktop prototype, called Magic Desk, demonstrating potential uses for multi-touch enabled desktop configurations.},
 keywords = {desktop work, multi-touch, tabletop},
} 
@inproceedings{Yang:2011:TouchCutsAndTouchZoom,
 author = {Yang, Xing-Dong and Grossman, Tovi and Irani, Pourang and Fitzmaurice, George},
 title = {TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2585--2594},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979319},
 doi = {http://doi.acm.org/10.1145/1978942.1979319},
 acmid = {1979319},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Although touch-screen laptops are increasing in popularity, users still do not comfortably rely on touch in these environments, as current software interfaces were not designed for being used by the finger. In this paper, we first demonstrate the benefits of using touch as a complementary input modality along with the keyboard and mouse or touchpad in a laptop setting. To alleviate the frustration users experience with touch, we then design two techniques, TouchCuts, a single target expansion technique, and ,i>TouchZoom,/i>, a multiple target expansion technique. Both techniques facilitate the selection of small icons, by detecting the finger proximity above the display surface, and expanding the target as the finger approaches. In a controlled evaluation, we show that our techniques improve performance in comparison to both the computer mouse and a baseline touch-based target acquisition technique. We conclude by discussing other application scenarios that our techniques support.},
 keywords = {target expansion, touch input},
} 
@inproceedings{Rohs:2011:InteractionWithMagicLenses,
 author = {Rohs, Michael and Oulasvirta, Antti and Suomalainen, Tiia},
 title = {Interaction with magic lenses: real-world validation of a Fitts' Law model},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2725--2728},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979343},
 doi = {http://doi.acm.org/10.1145/1978942.1979343},
 acmid = {1979343},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Rohs and Oulasvirta (2008) proposed a two-component Fitts' law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R2=0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R2 of 0.80, and when using effective target width an R2 of 0.88 was achieved.},
 keywords = {Fitt's Law, augmented reality, field experiment, human-performance modeling, magic lens pointing, target acquisition},
} 
@inproceedings{Yamashita:2011:SupportingFluidTabletopCollaborationAcrossDistances,
 author = {Yamashita, Naomi and Kuzuoka, Hideaki and Hirata, Keiji and Aoyagi, Shigemi and Shirai, Yoshinari},
 title = {Supporting fluid tabletop collaboration across distances},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2827--2836},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979362},
 doi = {http://doi.acm.org/10.1145/1978942.1979362},
 acmid = {1979362},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In this study, we examine how remote collaborators' upper body view affects collaboration when people engage in multiparty fluid tabletop activities across distances. We experimentally investigated the effects of upper body view on four-person group tabletop collaboration, two-by-two at identical locations: shared tabletop vs. shared tabletop plus upper body view. Although previous research has often failed to illustrate the advantages of showing remote participants' upper body view, our study showed that task performance was significantly higher in conditions with upper body view. Furthermore, participants with upper body view tended to take a step away from their remote partners to effectively glance at them while taking a comparable perspective of the tabletop objects. Detailed analysis of the video recordings revealed that upper body view was effective for fluid tabletop collaboration because it helped achieve joint perspective and helped estimate the timing and rough location of subsequent tabletop activity.},
 keywords = {group-to-group collaboration, remote gesture, shared tabletop, upper body view, video-mediated communication},
} 
@inproceedings{Laufer:2011:PreziMeeting:CollaborationInAzoomableCanvasBasedEnvironment,
 author = {Laufer, Laszlo and Halacsy, Peter and Somlai-Fischer, Adam},
 title = {Prezi meeting: collaboration in a zoomable canvas based environment},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {749--752},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979673},
 doi = {http://doi.acm.org/10.1145/1979742.1979673},
 acmid = {1979673},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We are introducing a zoomable, canvas based editor called Prezi, in which multiple users can collaborate synchronously, and share a common workspace for various purposes. They can develop a presentation together, create a mindmap, a storyline or do brainstorming. In this paper we would like to describe our key ideas, when designing the user experience of the collaboration function. We are arguing that the use of avatars in zoomable user interfaces are providing a uniquely efficient environment for collaboration in productivity applications. This kind of representation in a ZUI collaboration environment is raising group awareness, articulation work, and also gamifies presentaion editing, facilitating casual interaction between the participants.},
 keywords = {ZUI, avatars, computer supported collaborativ work, gamification, presentation},
} 
@inproceedings{Cohe:2011:tBox:A3dTransformationWidgetDesignedForTouchcreens,
 author = {Coh\'{e}, Aur\'{e}lie and D\`{e}cle, Fabrice and Hachet, Martin},
 title = {tBox: a 3d transformation widget designed for touch-screens},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3005--3008},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979387},
 doi = {http://doi.acm.org/10.1145/1978942.1979387},
 acmid = {1979387},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={3D transformation widgets are commonly used in many 3D applications operated from mice and keyboards. These user interfaces allow independent control of translations, rotations, and scaling for manipulation of 3D objects. In this paper, we study how these widgets can be adapted to the tactile paradigm. We have explored an approach where users apply rotations by means of physically plausible gestures, and we have extended successful 2D tactile principles to the context of 3D interaction. These investigations led to the design of a new 3D transformation widget, tBox, that can been operated easily and efficiently from gestures on touch-screens.},
 keywords = {3d transformation widget, 3d user interfaces, multi-touch},
} 
@inproceedings{Lee:2011:EvaluatingEXtremeScenarioBasedDesignInADistributedAgileTeam,
 author = {Lee, Jason Chong and Judge, Tejinder K. and McCrickard, Donald Scott},
 title = {Evaluating eXtreme scenario-based design in a distributed agile team},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {863--877},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/1979742.1979681},
 doi = {http://doi.acm.org/10.1145/1979742.1979681},
 acmid = {1979681},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Enterprise-level organizations, which often rely on distributed development teams, are increasingly interested in finding ways to adopt agile and usability-focused methods. Agile usability researchers at Virginia Tech have partnered with Meridium, Inc. to look at how eXtreme Scenario-based Design (XSBD), an agile usability approach developed at Virginia Tech, can be used in a distributed environment. We report on the use of this XSBD approach in a distributed team at Meridium and how it addresses the challenges of an integrated approach through streamlined usability and development practices and clearly defined communication and information sharing practices.},
 keywords = {agile, distributed development, extreme scenario-based design, usability, xsbd},
} 

@inproceedings{Lee:2011:EES:1979602.1979681,
 author = {Lee, Jason Chong and Judge, Tejinder K. and McCrickard, Donald Scott},
 title = {Evaluating eXtreme scenario-based design in a distributed agile team},
 booktitle = {PART 1 ---------- Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {863--877},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/1979602.1979681},
 doi = {http://doi.acm.org/10.1145/1979602.1979681},
 acmid = {1979681},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Enterprise-level organizations, which often rely on distributed development teams, are increasingly interested in finding ways to adopt agile and usability-focused methods. Agile usability researchers at Virginia Tech have partnered with Meridium, Inc. to look at how eXtreme Scenario-based Design (XSBD), an agile usability approach developed at Virginia Tech, can be used in a distributed environment. We report on the use of this XSBD approach in a distributed team at Meridium and how it addresses the challenges of an integrated approach through streamlined usability and development practices and clearly defined communication and information sharing practices.},
 keywords = {agile, distributed development, extreme scenario-based design, usability, xsbd},
} 
@inproceedings{Jetter:2011:MaterializingTheQueryWithFacetStreams:,
 author = {Jetter, Hans-Christian and Gerken, Jens and Z\"{o}llner, Michael and Reiterer, Harald and Milic-Frayling, Natasa},
 title = {Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3013--3022},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979390},
 doi = {http://doi.acm.org/10.1145/1978942.1979390},
 acmid = {1979390},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We introduce "Facet-Streams", a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.},
 keywords = {collaborative search, tabletop, tangible user interfaces}
} 
@inproceedings{Jetter:2011:MQF:1978942.1979390,
 author = {Jetter, Hans-Christian and Gerken, Jens and Z\"{o}llner, Michael and Reiterer, Harald and Milic-Frayling, Natasa},
 title = {Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3013--3022},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979390},
 doi = {http://doi.acm.org/10.1145/1978942.1979390},
 acmid = {1979390},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We introduce "Facet-Streams", a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.},
 keywords = {collaborative search, tabletop, tangible user interfaces},
} 
@inproceedings{Hinrichs:2011:GesturesInTheWild,
 author = {Hinrichs, Uta and Carpendale, Sheelagh},
 title = {Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3023--3032},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979391},
 doi = {http://doi.acm.org/10.1145/1978942.1979391},
 acmid = {1979391},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In this paper we describe our findings from a field study that was conducted at the Vancouver Aquarium to investigate how visitors interact with a large interactive table exhibit using multi-touch gestures. Our findings show that the choice and use of multi-touch gestures are influenced not only by general preferences for certain gestures but also by the interaction context and social context they occur in. We found that gestures are not executed in isolation but linked into sequences where previous gestures influence the formation of subsequent gestures. Furthermore, gestures were used beyond the manipulation of media items to support social encounters around the tabletop exhibit. Our findings indicate the importance of versatile many-to-one mappings between gestures and their actions that, other than one-to-one mappings, can support fluid transitions between gestures as part of sequences and facilitate social information exploration.},
 keywords = {direct-touch interaction, field study, multi-touch gestures, public displays, tabletop displays},
} 
@inproceedings{Marshall:2011:RethinkingMultiUserTabletop,
 author = {Marshall, Paul and Morris, Richard and Rogers, Yvonne and Kreitmayer, Stefan and Davies, Matt},
 title = {Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3033--3042},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979392},
 doi = {http://doi.acm.org/10.1145/1978942.1979392},
 acmid = {1979392},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Multi-touch tabletops have been much heralded as an innovative technology that can facilitate new ways of group working. However, there is little evidence of these materialising outside of research lab settings. We present the findings of a 5-week in-the-wild study examining how a shared planning application - designed to run on a walk-up-and-use tabletop - was used when placed in a tourist information centre. We describe how groups approached, congregated and interacted with it and the social interactions that took place - noting how they were quite different from research findings describing the ways groups work around a tabletop in lab settings. We discuss the implications of such situated group work for designing collaborative tabletop applications for use in public settings.},
 keywords = {in situ, in-the-wild, public, tabletop, walk-up-and-use},
} 
@inproceedings{Jamil:2011:TheEffectsOfInteractionTechniquesOnTalkPatternsInCollaborativePeerLearningAroundInteractiveTables,
 author = {Jamil, Izdihar and O'Hara, Kenton and Perry, Mark and Karnik, Abhijit and Subramanian, Sriram},
 title = {The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3043--3052},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979393},
 doi = {http://doi.acm.org/10.1145/1978942.1979393},
 acmid = {1979393},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper presents the findings of a user study investigating conversational patterns across three conditions of table-based interaction (direct touch interactive table, pantograph interactive table and non-digital table) for different types of educational activities. Findings demonstrate that communication style is significantly affected by interaction techniques. The direct touch technique stimulated conversations based around the topic and pedagogical method. The pantograph technique promoted playfulness and had a higher number of directive utterances between participants, with fewer task-based, group-oriented utterances. The non-digital table promoted reflective forms of task-orientated utterance, encouraged group communication and fostered more equitable participation between members. The findings provide insights into the design of interactive tables to support particular forms of social interaction.},
 keywords = {children, collaborative learning, communication, interaction techniques, tabletop},
} 
@inproceedings{Gjerlufsen:2011:SharedSubstanceDevelopingFlexibleMultisurfaceApplications,
 author = {Gjerlufsen, Tony and Klokmose, Clemens Nylandsted and Eagan, James and Pillias, Cl\'{e}ment and Beaudouin-Lafon, Michel},
 title = {Shared substance: developing flexible multi-surface applications},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3383--3392},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979446},
 doi = {http://doi.acm.org/10.1145/1978942.1979446},
 acmid = {1979446},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper presents a novel middleware for developing flexible interactive multi-surface applications. Using a scenario-based approach, we identify the requirements for this type of applications. We then introduce Substance, a data-oriented framework that decouples functionality from data, and Shared Substance, a middleware implemented in Substance that provides powerful sharing abstractions. We describe our implementation of two applications with Shared Substance and discuss the insights gained from these experiments. Our finding is that the combination of a data-oriented programming model with middleware support for sharing data and functionality provides a flexible, robust solution with low viscosity at both design-time and run-time.},
 keywords = {data-oriented model, middleware, multi-surface interaction},
} 

@inproceedings{Gjerlufsen:2011:SSD:1979442.1979446,
 author = {Gjerlufsen, Tony and Klokmose, Clemens Nylandsted and Eagan, James and Pillias, Cl\'{e}ment and Beaudouin-Lafon, Michel},
 title = {Shared substance: developing flexible multi-surface applications},
 booktitle = {PART 5 -------- Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 location = {Vancouver, BC, Canada},
 pages = {3383--3392},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1979442.1979446},
 doi = {http://doi.acm.org/10.1145/1979442.1979446},
 acmid = {1979446},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper presents a novel middleware for developing flexible interactive multi-surface applications. Using a scenario-based approach, we identify the requirements for this type of applications. We then introduce Substance, a data-oriented framework that decouples functionality from data, and Shared Substance, a middleware implemented in Substance that provides powerful sharing abstractions. We describe our implementation of two applications with Shared Substance and discuss the insights gained from these experiments. Our finding is that the combination of a data-oriented programming model with middleware support for sharing data and functionality provides a flexible, robust solution with low viscosity at both design-time and run-time.},
 keywords = {data-oriented model, middleware, multi-surface interaction},
} 
@inproceedings{Tashman:2011:LiquidTextFlexibleMultitouchEnvironmentToSupportActiveReading,
 author = {Tashman, Craig S. and Edwards, W. Keith},
 title = {LiquidText: a flexible, multitouch environment to support active reading},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3285--3294},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979430},
 doi = {http://doi.acm.org/10.1145/1978942.1979430},
 acmid = {1979430},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers' activities. Most computer-based active reading support seeks to replicate the affordances of paper, but paper has limitations, being in many ways inflexible. In this paper we introduce LiquidText, a computer-based active reading system that takes a fundamentally different approach, offering a flexible, fluid document representation built on multitouch input, with a range of interaction techniques designed to facilitate the activities of active reading. We report here on our design for LiquidText, its interactions and gesture vocabulary, and our design process, including formative user evaluations which helped shape the final system.},
 keywords = {active reading, multitouch input, visualization},
} 
@inproceedings{Hunter:2011:MemTable:AnIntegratedSystemForCaptureAndRecallOfSharedHistoriesInGroupWorkspaces,
 author = {Hunter, Seth and Maes, Pattie and Scott, Stacey and Kaufman, Henry},
 title = {MemTable: an integrated system for capture and recall of shared histories in group workspaces},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3305--3314},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979432},
 doi = {http://doi.acm.org/10.1145/1978942.1979432},
 acmid = {1979432},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={This paper presents the design, implementation, and evaluation of an interactive tabletop system that supports co-located meeting capture and asynchronous search and review of past meetings. The goal of the project is to evaluate the design of a conference table that augments the everyday work patterns of small collaborative groups by incorporating an integrated annotation system. We present a holistic design that values hardware ergonomics, supports heterogeneous input modalities, generates a memory of all user interactions, and provides access to historical data on and off the table. We present a user evaluation that assesses the usefulness of the input modalities and software features, and validates the effectiveness of the MemTable system as a tool for assisting memory recall.},
 keywords = {capture and recall, ergonomics, history, meeting support, memory, memtable, surface computing},
} 
@inproceedings{Hutama:2011:DistinguishingMultipleSmartPhoneInteractionsOnMultitouchWall,
 author = {Hutama, William and Song, Peng and Fu, Chi-Wing and Goh, Wooi Boon},
 title = {Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {3315--3318},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1978942.1979433},
 doi = {http://doi.acm.org/10.1145/1978942.1979433},
 acmid = {1979433},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display. This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display. Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.},
 keywords = {collaborative interactions, multi-touch interaction, personal handheld device},
} 